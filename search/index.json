[{"content":"이번에 프로젝트를 수행하면서 일별로 데이터를 분석할 필요가 있었다.\n처음엔 수동으로 작업을 했는데 자동으로 구동되면 좋을 것 같아서 찾아보니 역시나 기능이 있었다.\n$ZEPPELIN_HOME/conf/zeppelin-site.xml 에서 주석으로 돼있는 내용을 풀고 다음과 같이 수정하면 된다.\n(zeppelin.notebook.cron.folders 에도 값이 있어야 하는데 / 나 특정 디렉토리를 입력했을 때는 버튼이 나오지 않았다.)\n\u0026lt;property\u0026gt; \u0026lt;name\u0026gt;zeppelin.notebook.cron.enable\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;true\u0026lt;/value\u0026gt; \u0026lt;description\u0026gt;Notebook enable cron scheduler feature\u0026lt;/description\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;zeppelin.notebook.cron.folders\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;*\u0026lt;/value\u0026gt; \u0026lt;description\u0026gt;Notebook cron folders\u0026lt;/description\u0026gt; \u0026lt;/property\u0026gt;  이미 설정된 값은 None, 1m, 5m, 1h, 3h, 6h, 12h, 1d로 돼있다.\n그외에 설정을 하려면 크론 설정은 Quatz에서 하는 것과 같이 하면 된다.\n10분마다로 설정을 하려며 0 0/10 * * * ? 로 하면 된다.\n참고 문헌  https://zeppelin.apache.org/docs/0.8.0/usage/other_features/cron_scheduler.html https://stackoverflow.com/questions/58727773/cant-turn-on-cron-feature-in-apache-zeppelin https://www.quartz-scheduler.org/documentation/quartz-2.3.0/tutorials/crontrigger.html#examples  ","date":"2020-08-27","permalink":"isprometheo.github.io/posts/75/","tags":["log","zeppelin","cron"],"title":"[Log] Zeppelin 크론 설정하기"},{"content":"ffmpeg을 이용하여 동영상을 인코딩하는 데스크톱 앱을 만들어야 했다.\n빠르게 만들기 위해 GitHub에 있을까하고 검색해보니 역시나 있었다.\n만드는 과정에서 추가로 필요했던 기능들은 다음과 같았다.\n 새로 고침 막기 메뉴 수정 asar로 빌드했을 때 실행 파일 불러오기  새로 고침을 막는 것은 우선 단축키가 아무 일도 하지 않도록 했다.\n그리고 기본 메뉴에 새로 고침이 있었는데 이것 역시 제거하면서 불필요한 메뉴들을 모두 없앴다.\nfluent-ffmpeg의 경우 ffmpeg 실행 파일을 불러 쓸 수 있었는데\nasar로 빌드하는 경우 실행 파일도 같이 포함되어 만들어지나 파일 실행은 할 수 없었다.\n그래서 ffmpeg, ffprobe 가 특정 디렉토리에 존재하도록 하고 이 디렉토리에 접근할 수 있어야 했다.\nextraFiles를 이용하여 특정 디렉토리에 파일을 복사할 수 있었다.\n그리고 getAppPath()로 특정 디렉토리에 접근하여 파일을 불러올 수 있었다.\n작성한 코드 일부는 다음과 같다.\nconst { app, globalShortcut, BrowserWindow, Menu } = require('electron'); const path = require('path'); const ffmpeg = require('fluent-ffmpeg'); const isPackaged = process.mainModule.filename.indexOf('app.asar') !== -1; if (process.platform === \u0026quot;darwin\u0026quot;) { if (isPackaged) { ffmpeg.setFfmpegPath(path.join(path.dirname(app.getAppPath()), '..', './Resources', 'bin/ffmpeg')); ffmpeg.setFfprobePath(path.join(path.dirname(app.getAppPath()), '..', './Resources', 'bin/ffprobe')); } else { ffmpeg.setFfmpegPath(path.join(__dirname, '.', 'bin/osx/ffmpeg')); ffmpeg.setFfprobePath(path.join(__dirname, '.', 'bin/osx/ffprobe')); } } else if (process.platform === 'win32') { ffmpeg.setFfmpegPath(path.join(__dirname, '.', 'bin/win32/ffmpeg.exe')); ffmpeg.setFfprobePath(path.join(__dirname, '.', 'bin/win32/ffprobe.exe')); } else { ffmpeg.setFfmpegPath(path.join(__dirname, '.', 'bin/win64/ffmpeg.exe')); ffmpeg.setFfprobePath(path.join(__dirname, '.', 'bin/win64/ffprobe.exe')); } const createWindow = () =\u0026gt; { const win = new BrowserWindow({ width: 800, height: 600, webPreferences: { nodeIntegration: true, devTools: false } }); const isMac = process.platform === 'darwin'; const template = [ ...(isMac ? [{ label: app.name, submenu: [ { role: 'about' }, { type: 'separator' }, { role: 'hide' }, { role: 'hideothers' }, { role: 'unhide' }, { type: 'separator' }, { role: 'quit' } ] }] : []), { role: 'help', submenu: [ { label: 'Learn More', click: async () =\u0026gt; { await shell.openExternal('https://electronjs.org'); } } ] } ]; const menu = Menu.buildFromTemplate(template); Menu.setApplicationMenu(menu); win.setMenuBarVisibility(false); win.loadFile('index.html'); win.webContents.openDevTools(); } app.whenReady().then(createWindow); app.on('browser-window-focus', () =\u0026gt; { globalShortcut.register('CommandOrControl+R', () =\u0026gt; { console.log('CommandOrControl+R is pressed: Shortcut Disabled'); }); globalShortcut.register('F5', () =\u0026gt; { console.log('F5 is pressed: Shortcut Disabled'); }); }); app.on('browser-window-blur', () =\u0026gt; { globalShortcut.unregister('CommandOrControl+R'); globalShortcut.unregister('F5'); });  \u0026quot;build\u0026quot;: { \u0026quot;productName\u0026quot;: \u0026quot;My App\u0026quot;, \u0026quot;appId\u0026quot;: \u0026quot;com.my.app\u0026quot;, \u0026quot;files\u0026quot;: [ \u0026quot;!bin/*\u0026quot; ], \u0026quot;extraFiles\u0026quot;: [ { \u0026quot;from\u0026quot;: \u0026quot;bin/osx\u0026quot;, \u0026quot;to\u0026quot;: \u0026quot;Resources/bin\u0026quot;, \u0026quot;filter\u0026quot;: [ \u0026quot;**/*\u0026quot; ] } ], \u0026quot;asar\u0026quot;: true, \u0026quot;protocols\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;myapp\u0026quot;, \u0026quot;schemes\u0026quot;: [ \u0026quot;myapp\u0026quot; ] }, \u0026quot;mac\u0026quot;: { \u0026quot;target\u0026quot;: [ \u0026quot;dmg\u0026quot; ], \u0026quot;icon\u0026quot;: \u0026quot;resources/icon.icns\u0026quot; }, \u0026quot;dmg\u0026quot;: { \u0026quot;internetEnabled\u0026quot;: true }, \u0026quot;win\u0026quot;: { \u0026quot;target\u0026quot;: [ \u0026quot;zip\u0026quot;, \u0026quot;nsis\u0026quot; ], \u0026quot;icon\u0026quot;: \u0026quot;./resources/icon.ico\u0026quot; }, \u0026quot;nsis\u0026quot;: { \u0026quot;oneClick\u0026quot;: false, \u0026quot;allowToChangeInstallationDirectory\u0026quot;: true }, \u0026quot;directories\u0026quot;: { \u0026quot;buildResources\u0026quot;: \u0026quot;./resources/installer/\u0026quot;, \u0026quot;output\u0026quot;: \u0026quot;./dist/\u0026quot;, \u0026quot;app\u0026quot;: \u0026quot;.\u0026quot; } }  참고 문헌  https://github.com/likethemammal/electron-ffmpeg-example https://ffmpeg.zeranoe.com/builds/ https://github.com/fluent-ffmpeg/node-fluent-ffmpeg https://www.electronjs.org/docs/api/menu https://discuss.atom.io/t/prevent-browserwindow-from-reloading/20541/3  ","date":"2020-08-13","permalink":"isprometheo.github.io/posts/74/","tags":["electron","ffmpeg"],"title":"[JS] Electron으로 앱 만들기"},{"content":"Go 프로젝트에서 http 클라이언트를 만들어서 활용하고 있었는데 어느 날 서버에 응답이 없었다.\n그래서 서버에 들어가서 확인해보니 too many open files라는 에러가 나고 있었다.\nnetstat으로 확인해보니 CLOSE_WAIT 상태로 많이 쌓여 있었다.\n어디가 문제인가 살펴보니 defer resp.Body.Close() 를 하는데 상태값이 200인 경우에만 닫도록 돼있었다.\n(문서에서 Body를 읽은 경우엔 항상 닫아주라고 써있다.)\nresp, err := http.Get(\u0026quot;http://example.com/\u0026quot;) if err != nil { return } else if resp.StatusCode != 200 { return } defer resp.Body.Close()  다음과 같이 수정한 이후 경과를 살펴보니 잘 동작하는 것을 확인할 수 있었다.\nresp, err := http.Get(\u0026quot;http://example.com/\u0026quot;) if err != nil { return } defer resp.Body.Close() if resp.StatusCode != 200 { return }  참고 문헌  https://golang.org/pkg/net/http/  ","date":"2020-08-06","permalink":"isprometheo.github.io/posts/73/","tags":["golang","http","get","close"],"title":"[Golang] too many open files 에러 해결"},{"content":"echo 프레임워크로 파일 업로더 서버를 구축했다.\n쿡북에서 단일 파일, 여러 파일을 업로드하는 예제가 있어 이를 바탕으로 쉽게 만들 수 있었다.\n하지만 업로드를 하는 클라이언트에서 폼의 키값을 다른 것으로 하는 경우를 고려해야 했다.\n그래서 여러 파일을 업로드하는 코드를 참고하여 입맛에 맞게 수정했다.\nfunc upload(c echo.Context) error { form, err := c.MultipartForm() if err != nil { return err } for _, file := range form.File { // Source src, err := file[0].Open() if err != nil { return err } defer src.Close() // Destination dst, err := os.Create(file[0].Filename) if err != nil { return err } defer dst.Close() // Copy if _, err = io.Copy(dst, src); err != nil { return err } } }  그리고 용량이 큰 파일을 업로드하는 경우에 디스크 사용량이 파일 사이즈의 2배가 늘어났다.\n원인을 찾아보니 echo에서 설정한 메모리(32 MB)보다 큰 경우 /tmp/에 파일을 저장하고 있었다.\n다음과 같이 하면 파일을 원하는 곳에 복사한 다음 임시 파일을 모두 제거할 수 있다.\ndefer func() { form, err := ctx.MultipartForm() if err != nil { return } form.RemoveAll() }()  참고 문헌  https://echo.labstack.com/cookbook/file-upload https://github.com/labstack/echo/blob/master/context.go#L369 https://github.com/golang/go/blob/master/src/mime/multipart/formdata.go#L86  ","date":"2020-07-30","permalink":"isprometheo.github.io/posts/72/","tags":["golang","echo","file","upload"],"title":"[Golang] Echo 파일 업로더 서버 구축"},{"content":"저번에 해결이 된 줄 알고 좋아했지만 곧 정책 위반으로 삭제가 됐다.\n이번엔 확실히 해결하기 위해 더 가열차게 검색을 하여 찾아봤다.\nReact Native의 라이프 사이클을 다시 한번 확인했다.\n앱이 로딩되는 중에 광고를 가져오면 안된다고 하여 어느 시점에 해야하는지 살펴봤다.\n기존에는 constructor에서 호출하고 있었고 setTimeout으로 했지만\n아직 앱이 로딩 중이기에 구글에서 위반이라고 판단한 것 같았다.\n그래서 확실하게 componentDidMount에서 호출하여 광고를 가져오도록 했다.\n그리고 앱 시작하고 스플래시 화면 다음에 전면 광고가 나오도록 했는데\n광고를 가져오는 시점이 변경되어 광고를 나오게 하는 시점도 변경했다.\n2주 정도 지난 현재까지 위반 메일이 오지않는 것으로 봐서 해결된 것 같다.\n참고 문헌  https://projects.wojtekmaj.pl/react-lifecycle-methods-diagram/ https://support.google.com/admob/answer/6201362?ref_topic=2745287  ","date":"2020-07-23","permalink":"isprometheo.github.io/posts/71/","tags":["playstore","정책위반"],"title":"[PlayStore] 앱, 타사 광고, 기기 기능 방해 정책 위반 처리(3)"},{"content":"서버를 구성하는데 mediainfo와 ffmpeg을 설치할 필요가 있었다.\n설치할 서버가 적을 경우 하나씩 해도 되지만 서버가 많을 경우 일일이 하는 것이 어렵다.\n이를 쉽게 하기 위해 자동화 도구 중에 하나인 Ansible을 사용했다.\n많은 명령어들을 지원하는데 yum으로만 진행하여 다음과 같이 설정 파일을 만들었다.\n- hosts: \u0026quot;{{ host }}\u0026quot; tasks: - name: install epel-release yum: name: epel-release state: present become: yes become_user: root - name: localinstall rpmfusion-free-release-7 yum: name: https://download1.rpmfusion.org/free/el/rpmfusion-free-release-7.noarch.rpm disable_gpg_check: yes state: present become: yes become_user: root - name: install mediainfo yum: name: mediainfo state: present become: yes become_user: root - name: install ffmpeg yum: name: ffmpeg state: present become: yes become_user: root  state는 yum과 같이 사용하는 값인데 absent, installed, latest, present, removed이 있다.\npresent, installed, latest는 설치를 진행하고 absent, removed는 패키지를 제거한다.\nbecome과 become_user를 사용하여 사용자를 전환할 수 있으며 become_user는 root가 기본값이다.\nyum 프록시 설정이 필요한 경우 yum.conf를 수정해야하는데 lineinfile을 사용하여 쉽게 수정할 수 있다.\n- hosts: \u0026quot;{{ host }}\u0026quot; tasks: - name: proxy added to /etc/yum.conf lineinfile: path: /etc/yum.conf regexp: 'proxy=' insertafter: '\\[main\\]' line: 'proxy=proxy_addr' state: present become: yes become_user: root  regexp는 찾으려는 문자열의 정규식이며 insertafter에 해당 문자열 다음에\nstate가 present인 경우 line의 값을 추가한다.\nstate는 absent, present가 있는데 absent는 line을 제거하고 present는 추가한다.\n참고 문헌  https://linuxize.com/post/how-to-install-ffmpeg-on-centos-7/ https://docs.ansible.com/ansible/latest/modules/yum_module.html https://docs.ansible.com/ansible/latest/modules/lineinfile_module.html  ","date":"2020-07-16","permalink":"isprometheo.github.io/posts/70/","tags":["ansible","mediainfo","ffmepeg"],"title":"[Ansible] ansible로 mediainfo ffmepeg 설치"},{"content":"또 앱이 삭제됐다.\n이번에도 \u0026ldquo;앱, 타사 광고, 기기 기능 방해 정책 위반 처리\u0026quot;로 인해 삭제됐다.\n그래서 앱 시작과 동시에 전면 광고가 나오지 않도록 했다.\n대신에 아이콘은 클릭했을 때 전면 광고가 노출되도록 변경해서 제출했다.\n제출하고 하루가 지나서 앱이 다시 정상적으로 플레이 스토어에 노출된다는 메일을 받았다.\n그러나 몇시간 뒤 다시 같은 이유로 삭제됐다.\n도대체 무엇이 문제인가 싶어 찬찬히 코드와 광고가 나오는 타이밍 등을 살펴보려 했다.\n광고가 나오는 타이밍을 보려고 테스트 광고 ID로 해봤지만 삭제돼서 그런지 광고가 나오지 않았다.\n그러다 스택 오버플로우에서 이 이슈를 해결할 수 있을 것 같은 방법을 찾았다.\n해당 내용에서 이 이슈가 발생하는 이유는 앱이 백그라운드에 있을 때\n(광고를 보여주지 않아도) 광고 소재를 호출하는 것만으로도 위반으로 판단하기 때문이라고 했다\n현재 앱에서 전면 광고를 미리 불러오는데 constructor에서 수행하고 있었다.\n디버깅을 해보니 앱이 백그라운드로 넘어갔을 때도 호출하는 것을 확인할 수 있었다.\n그래서 AppState 확인하는 부분에서 처리해보려고 했는데\nbackground에서 active일 때는 잘 됐지만 active 상태가 유지되는 경우엔 동작하지 않았다. (상태가 변경돼야 동작하기 때문)\n어떻게 하면 두 상황 모두 가능하게 할 수 있을까 하다가 setTimeout으로 쉽게 해결할 수 있었다.\n일정 시간 동안 앱이 active면 불러오고 시작과 동시에 백그라운드로 넘어갔을 때는 불러오지 않는 것을 확인했다.\nconstructor() { setTimeout(() =\u0026gt; { if (this.state.appState) { interstitial.load(); } }, SLEEP_TIME); } _handleAppStateChange = nextAppState =\u0026gt; { if (this.state.appState.match(/inactive|background/) \u0026amp;\u0026amp; nextAppState === 'active') { interstitial.load(); } this.setState({ appState: nextAppState }); };  이번에는 꼭 제발 성공하기를 빌었고 이틀 정도가 지나 다시 정상적으로 등록됐다는 메일을 받을 수 있었다.\n참고 문헌  https://stackoverflow.com/questions/57251947/uncaught-exception-thrown-by-finalizer-all-webview-methods-must-be-called-on-th/57308639#57308639  ","date":"2020-07-09","permalink":"isprometheo.github.io/posts/69/","tags":["playstore","정책위반"],"title":"[PlayStore] 앱, 타사 광고, 기기 기능 방해 정책 위반 처리(2)"},{"content":"신규 서버를 만들면서 두가지 기능이 필요했다.\n첫째는 명령어를 동시에 실행해서 속도를 높이는 것과 데이터가 있는 디렉토리를 제거하는 것이었다.\n 명령어 동시 실행하기  Golang에서 WaitGroup은 모든 goroutine이 종료될 때까지 기다린다.\n채널을 통해서 커맨드를 전달하고 goroutine에서 이 커맨드를 실행하고 종료한다.\n명령어를 단순 반복문으로 수행하면 오래 걸리지만 이를 활용하면 빠르게 수행할 수 있었다.\ntasks := make(chan *exec.Cmd, 64) var wg sync.WaitGroup for i := 0; i \u0026lt; 10; i++ { wg.Add(1) go func(w *sync.WaitGroup) { defer w.Done() for cmd := range tasks { out, err := cmd.Output() if err != nil { fmt.Println(\u0026quot;can't get stdout: %v\u0026quot;, err) } fmt.Println(string(out)) } }(\u0026amp;wg) } for i := 0; i \u0026lt; 10; i++ { tasks \u0026lt;- exec.Command(\u0026quot;echo\u0026quot;, strconv.Itoa(i)) } close(tasks) wg.Wait()  디렉토리 제거(rm -rf)  간단하게 exec.Command를 활용하면 되겠지만 최대한 Golang 함수로 해결해보려고 했다.\n그래서 아래와 같이 디렉토리 밑의 데이터를 지우고 마지막으로 디렉토리를 삭제하도록 했다.\nfunc removeContents(dir string) error { d, err := os.Open(dir) if err != nil { return err } defer d.Close() names, err := d.Readdirnames(-1) if err != nil { return err } for _, name := range names { err = os.RemoveAll(filepath.Join(dir, name)) if err != nil { return err } } syscall.Rmdir(dir) return nil }  참고 문헌  https://stackoverflow.com/questions/40247726/go-execute-a-bash-command-n-times-using-goroutines-and-store-print-its-resul https://stackoverflow.com/questions/33450980/how-to-remove-all-contents-of-a-directory-using-golang  ","date":"2020-07-02","permalink":"isprometheo.github.io/posts/68/","tags":["golang","waitgroup","디렉토리 제거"],"title":"[Golang] 커맨드 명령 동시 실행 및 디렉토리 제거"},{"content":"갑작스럽게 앱이 삭제됐다.\n\u0026ldquo;앱, 타사 광고, 기기 기능 방해 정책 위반 처리\u0026rdquo; 으로 검색을 해봤다.\n여러 가지 많은 결과들이 있었지만 같은 경우가 잘 없어 어떻게 대처해야할지 몰랐다.\n메타 데이타나 정책 설정 문제인듯 싶어 관련된 것들을 수정했다.\n하지만 거부됐다는 메일을 다시 받았다.\n앱 버전을 올려서 제출하면 될 수도 있다는 말이 있어 해봤지만 역시 거절당했다.\n예전에 개인정보처리방침으로 삭제된 적이 있어 이를 다시 업데이트해봤지만 소용없었다.\n그래서 문서를 다시 읽어 봤다.\n혹시나 하는 생각에 전면 광고를 앱이 실행 중일 때만 나오도록 수정하려고 했다.\n이를 위해서 앱이 활성 상태인지를 확인하는 것이 필요했는데 다행히 React Native에서 지원했다.\nAppState를 사용해서 쉽게 현재 상태가 active인지 background인지를 알 수 있어\n이를 사용해 백그라운드로 변경되는 경우 광고가 나오지 않도록 수정해서 제출했다.\nis live in the store.  다행히 다시 정상적으로 등록됐다는 메일을 받았다.\n참고 문헌  https://stackoverflow.com/questions/54981212/react-native-how-to-detect-home-button-is-pressed-or-not https://reactnative.dev/docs/appstate  ","date":"2020-06-25","permalink":"isprometheo.github.io/posts/67/","tags":["playstore","정책위반"],"title":"[PlayStore] 앱, 타사 광고, 기기 기능 방해 정책 위반 처리"},{"content":"서버에 특정 프로그램이 CPU를 과도하게 사용하여 이를 안정시킬 필요가 있었다.\n이를 위해서 작업 중인 프로그램을 찾아서 우선 순위를 재조정하여 CPU 사용량을 낮출 수 있었다.\n$ ps -eo pid,nice,lstart,cmd | grep my_program | grep -v grep $ sudo renice -n 1 pid  lstart는 시작한 시간을 연월일시분초로 알려줘 날짜가 지나도 언제부터 시작된 프로세스인지를 알려준다.\n그리고 디스크 사용을 많이 하여 데이터를 제거해야 했다.\n특정 시간 이전 데이터를 지우기 위해 다음과 같이 명령어를 입력하여 해결할 수 있었다.\n$ find . -newermt \u0026quot;2020-06-17 00:00:00\u0026quot; ! -newermt \u0026quot;2020-06-18 00:00:00\u0026quot; | xargs rm -rf  참고 문헌  https://chloro.tistory.com/106 http://dveamer.github.io/linux/ProcessStatus.html https://superuser.com/questions/580273/ubuntu-linux-find-files-between-specific-times  ","date":"2020-06-18","permalink":"isprometheo.github.io/posts/66/","tags":["linux","서버","장애","대응"],"title":"[Linux] 서버 장애 대응"},{"content":"특정 기능을 위해 크롬 확장 프로그램을 제작하여 등록해야 했다.\n확장 프로그램을 등록하는 방법은 검색을 하면 어떻게 하는지 나와서 쉽게 할 수 있었다.\n하지만 처음 등록을 해보는 거라 그런지 다음과 같은 이유로 거부당했다.\n'스팸 및 스토어 내 게재위치' 항목의 설명 필드가 비어 있거나 아이콘 또는 스크린샷이 누락되어 있거나 항목이 의심스러워 보입니다.  처음엔 아이콘을 등록하지 않아서 아이콘을 등록을 해서 다시 시도했지만 같은 이유로 거부당했다.\n그 다음엔 홈페이지 URL, 지원 URL 항목을 채운 다음 진행했지만 또 거부당했다.\n혹시 공식 URL 항목을 적지 않아 그런가 싶어 구글 서치 콘솔에 웹사이트를 등록한 다음 재시도했지만 마찬가지였다.\n계속 거부를 당해서 문서를 다시 한번 찬찬히 읽어보았다.\nKeyword Spam: We don't allow extensions with misleading, improperly formatted, non-descriptive, irrelevant, excessive, or inappropriate metadata, including but not limited to the extension’s description, developer name, title, icon, screenshots, and promotional images. Developers must provide a clear and well-written description. We also don't allow unattributed or anonymous user testimonials in the app's description.  읽어보니 설명 등에 반복적인 문구를 허락하지 않는다는 것을 알 수 있었다.\n요약과 설명 항목을 비슷하게 작성했는데 이것때문에 게시가 안됐던 것이었다.\n설명을 가다듬어서 작성한 다음 재심사를 요청해보니 게시되는 것을 확인할 수 있었다.\n참고 문헌  https://developer.chrome.com/webstore/program_policies#spam  ","date":"2020-06-11","permalink":"isprometheo.github.io/posts/65/","tags":["chrome","extension","webstore","크롬","확장","프로그램","웹스토어","등록"],"title":"[Chrome] 크롬 확장 프로그램 웹스토어에 등록하기"},{"content":"1. 각 패키지는 단일 목적을 수행하라 2. 명시적으로 에러를 다뤄라 3. 깊게 중첩하는 것보다 빠르게 반환하라 4. 호출자에게 동시성을 맡겨라 5. goroutine을 실행하기 전, 언제 멈출지 알라 6. 패키지 수준의 상태를 피하라 7. 단순함은 중요하다 8. 패키지 API의 제약을 위해 테스트 코드를 작성하라 9. 느리다고 생각되면 우선 벤치마크로 증명하라 10. 중용은 미덕이다 11. 유지 보수를 생각하라 참고 문헌  https://the-zen-of-go.netlify.app  ","date":"2020-06-04","permalink":"isprometheo.github.io/posts/64/","tags":["golang","go","zen","선"],"title":"[Golang] Go의 선(The Zen of Go)"},{"content":"ElasticSearch에서 다음과 같은 로그가 발생했었다.\n[WARN ][o.e.d.i.m.MapperService ] [_default_] mapping is deprecated since it is not useful anymore now that indexes cannot have more than one type  이 로그는 _default_ mapping을 사용해서 발생하는 문제로\n6.0.0 부터 Deprecated 되어 실제 적용된 매핑 타입으로 적용하면 된다.\n그러나 \u0026ldquo;실제 적용된 매핑 타입으로 적용\u0026quot;을 어떻게 해야하는지 찾을 수 없었다.\nmapping api로 되는지도 해봤지만 전혀 되지 않았고 Kibana 설정으로도 변경을 할 수 없었다.\n인덱스를 새로 만들어서 복사해보라는 것도 있어 이를 해봤지만 이것 역시 _default_가 생겼다.\n그러다가 다른 인덱스에서는 발생을 안하는데 logstash 로 시작하는 인덱스에서만 _default_가 있어\n인덱스 이름에 logstash 를 다른 이름으로 변경하여 저장해보니 _default_가 만들어지지 않았다.\n정확한 이유는 모르겠지만 logstash로 시작되는 인덱스의 경우에는 _default_가 생성되는 것으로 보여진다.\n참고 문헌  https://www.elastic.co/guide/en/elasticsearch/reference/6.4/default-mapping.html  ","date":"2020-05-28","permalink":"isprometheo.github.io/posts/63/","tags":["log","elasticsearch","_default_","mapping"],"title":"[Log] ElasticSearch _default_ mapping 문제 해결"},{"content":"Emacs에서 magit을 사용하여 github를 이용하고 있는데 github의 다른 기능들도 사용하고 싶어졌다.\n특히 이슈를 등록하거나 보는 것을 하고 싶어 찾아보니 magithub라는 것이 있었다.\n.authinfo나 .authinfo.gpg를 사용하여 인증을 하는데\n.authinfo의 경우 평문으로 돼있어 보안을 생각하면 .authinfo.gpg를 사용하는 것이 좋다.\n토큰은 github에서 여기에서 만들고 .authinfo는 다음과 같이 만들면 된다.\nmachine api.github.com login YOUR_GITHUB_USERNAME^magithub password YOUR_GITHUB_TOKEN  그리고 이것을 Emacs에서 M-x \u0026gt; epa-encrypt-file로 .authinfo.gpg를 만들 수 있다.\nmacos에서 명령어가 없는 경우 brew install gpg로 설치하면 된다.\n또는 이곳에서 운영 체제에 맞게 다운로드받아 설치하면 된다.\nGPG key를 만들어서 github에 등록하는 것은 여기를 참고하면 된다.\n.authinfo.gpg로 하려는 경우 다음과 같은 오류가 발생할 수 있다.\ngpg: decryption failed: No secret key  이럴 때는 다음을 .emacs나 init.el에 추가한 다음 eval-buffer를 하면 된다.\n(setf epa-pinentry-mode 'loopback)  Gihub Enterprise에서 사용하는 것은 Github에서 하는 것과 같다.\n그리고 각각의 클론한 디렉토리에서 다음을 입력하면 된다.\ngit config github.host github.enterpise.domain/api/v3  참고 문헌  https://mrdias.com/2018/04/01/using-magit-with-github-enterprise.html https://emacs.stackexchange.com/questions/27841/unable-to-decrypt-gpg-file-using-emacs-but-command-line-gpg-works  ","date":"2020-05-21","permalink":"isprometheo.github.io/posts/62/","tags":["emacs","magithub"],"title":"[Emacs] magithub 사용하기"},{"content":"간단한 홈페이지를 구축해야할 필요가 있었는데\nGnuboard를 Docker 이미지로 만들어서 헤로쿠에 배포하고 싶었다.\n그래서 기존에 만들어진 것이 있는지 찾아보니 꽤 예전 버전이라 수정이 필요했다.\nDockerfile은 다음과 같이 만들었다.\nFROM ubuntu:20.04 ARG DEBIAN_FRONTEND=noninteractive # Run upgrades RUN echo \u0026quot;deb http://it.archive.ubuntu.com/ubuntu/ focal main universe\u0026quot; \u0026gt; /etc/apt/sources.list RUN apt-get update # Install basic packages RUN apt-get -qq -y install git curl build-essential # Install Apache2 RUN apt-get -qq -y install apache2 ENV APACHE_RUN_USER www-data ENV APACHE_RUN_GROUP www-data ENV APACHE_LOG_DIR /var/log/apache2 RUN a2enmod rewrite RUN sed -i -e \u0026quot;s/html/gnuboard5/\u0026quot; /etc/apache2/sites-available/000-default.conf # Install php RUN apt-get -qq -y install php7.4 RUN apt-get -qq -y install libapache2-mod-php7.4 php7.4-mysql php7.4-gd # Install Mysql RUN apt-get -qq -y install mysql-server mysql-client libmysqlclient-dev RUN sed -i -e \u0026quot;s/^bind-address\\s*=\\s*127.0.0.1/bind-address = 0.0.0.0/\u0026quot; /etc/mysql/my.cnf # Install Gnuboard5 COPY gnuboard5 /var/www/gnuboard5 EXPOSE 80 ADD boot.sh /boot.sh RUN chmod +x /boot.sh CMD [\u0026quot;/bin/bash\u0026quot;, \u0026quot;/boot.sh\u0026quot;]  이미지를 띄울 때 사용할 쉘 스크립트는 다음과 같이 작성했다.\n#/bin/bash # start mysql nohup mysqld_safe --skip-grant-tables \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 \u0026amp; sleep 10 echo \u0026quot;CREATE USER 'gnuboard'@'localhost' IDENTIFIED BY 'gnub0ard';\u0026quot; | mysql echo \u0026quot;CREATE DATABASE gnuboard;\u0026quot; | mysql echo \u0026quot;GRANT ALL PRIVILEGES ON gnuboard.* TO 'gnuboard'@'localhost' WITH GRANT OPTION;\u0026quot; | mysql # start apache2 sed -i \u0026quot;s/Listen 80/Listen ${PORT:-80}/g\u0026quot; /etc/apache2/ports.conf sed -i \u0026quot;s/:80/:${PORT:-80}/g\u0026quot; /etc/apache2/sites-available/* sed -i \u0026quot;s/:80/:${PORT:-80}/g\u0026quot; /etc/apache2/sites-enabled/* rm -f /etc/apache2/mods-enabled/mpm_event.load rm -f /etc/apache2/mods-enabled/mpm_event.conf source /etc/apache2/envvars /usr/sbin/apache2 -D FOREGROUND \u0026amp;  이렇게 작성해서 헤로쿠에 배포를 했으나 포트 번호가 계속 변경되는 문제로 되는 것만 확인하고 끝났다.\n참고 문헌  https://github.com/nacyot/docker-gnuboard5-mysql https://devcenter.heroku.com/articles/container-registry-and-runtime  ","date":"2020-05-14","permalink":"isprometheo.github.io/posts/61/","tags":["docker","gnuboard"],"title":"[Docker] Gnuboard 이미지 만들기"},{"content":"서버에 메모리가 부족하다는 알람이 발생해서 살펴보니 실제 사용하는 메모리는 적었다.\n그래서 다른 항목들을 보니 buff/cache에서 할당된 메모리가 80% 정도 사용하고 있었다.\n구글에서 찾아보니 다음과 같이 하면 바로 해제할 수 있었다.\n$ sudo sh -c \u0026quot;echo 1 \u0026gt; /proc/sys/vm/drop_caches\u0026quot;  참고 문헌  https://unix.stackexchange.com/questions/58553/how-to-clear-memory-cache-in-linux  ","date":"2020-05-07","permalink":"isprometheo.github.io/posts/60/","tags":["linux","buffer","cache"],"title":"[Linux] buff/cache 해제"},{"content":"Go로 만든 프로젝트에서 kafka 연동하여 로그를 수집하는데 confluent-kafka-go를 사용하고 있었다.\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;github.com/confluentinc/confluent-kafka-go/kafka\u0026quot; ) var kafkaClient *kafka.Producer func main() { kafkaClient, _ = kafka.NewProducer(\u0026amp;kafka.ConfigMap{ \u0026quot;bootstrap.servers\u0026quot;: \u0026quot;broker:9092\u0026quot;, \u0026quot;acks\u0026quot;: 1, }) go func() { for e := range p.Events() { switch ev := e.(type) { case *kafka.Message: m := ev if m.TopicPartition.Error != nil { fmt.Printf(\u0026quot;Delivery failed: %v, queue: %d\\n\u0026quot;, m.TopicPartition.Error, p.Len()) } return default: fmt.Printf(\u0026quot;Ignored event: %s\\n\u0026quot;, ev) } } }() } func SendMessage(topic string, message string) { kafkaClient.ProduceChannel() \u0026lt;- \u0026amp;kafka.Message{TopicPartition: kafka.TopicPartition{Topic: \u0026amp;topic, Partition: kafka.PartitionAny}, Value: []byte(message)} }  테스트를 했을 때 잘 동작하여 아무 문제가 없었지만 며칠간 실행시켜보니 Local: Queue full 에러가 나면서 더이상 메시지를 전송하지 못했다.\nqueue.buffering.max.messages 크기를 조절해가면서 테스트를 했지만 해당 에러가 계속 발생해 Flush()로 급한 불을 끌 수 있었다.\nlibrdkafka에서 쓰는 버퍼가 해제되지 않은 문제인 듯 했으나 정확한 원인을 몰라 더 이상의 사용이 불안하여 다른 라이브러리를 찾아봤다.\nShopify에서 만든 sarama가 유명하다고 추천받아 테스트를 해보고 적용하기로 했다.\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;github.com/Shopify/sarama\u0026quot; ) var kafkaClient sarama.AsyncProducer func main() { brokers := []string{\u0026quot;broker:9092\u0026quot;} kafkaClient, _ = sarama.NewAsyncProducer(brokers, nil) } func SendMessage(topic string, message string) { kafkaClient.Input() \u0026lt;- \u0026amp;sarama.ProducerMessage{ Topic: topic, Partition: -1, Value: sarama.StringEncoder(message), } }  테스트는 1000만건의 메시지를 전송하도록 진행했다.\nconfluent-kafka-go와 비교해보니 메모리를 더 적게 사용하면서 성능은 비슷했다.\nconfluent-kafka-go는 메모리를 20MB 정도 기본으로 사용하고 sarma는 최대 3MB를 사용했다.\nconfluent-kafka-go의 경우 Flush를 하지 않으면 GC를 수행해도 메모리가 조금씩 증가했지만\nsarama는 메모리가 증가하는 것 없이 동작을 잘 하는 것을 확인할 수 있었다.\n참고 문헌  https://github.com/confluentinc/confluent-kafka-go https://github.com/Shopify/sarama  ","date":"2020-04-30","permalink":"isprometheo.github.io/posts/59/","tags":["golang","kafka","confluent-kafka-go","sarama","localqueuefull"],"title":"[Golang] Kafka 연동 문제"},{"content":" 테스트 타임아웃  Go로 테스트를 하는데 다음과 같은 에러가 발생하면서 종료됐다.\ngolang panic: test timed out after 10m0s  이유는 테스트를 수행할 때 기본으로 10분으로 타임아웃이 걸려있었기 때문이었다.\n$ go test -timeout 1h  위와 같이 타임아웃 시간을 늘려서 수행하면 된다.\n410 gone  이전에 Go 버전을 올리고 410 Gone 에러가 나서 환경변수를 설정했었는데\ngo get으로 다운로드가 안되는 경우가 발생했다.\n비공개 저장소에서 받는 경우 발생하는 문제로\n다음과 같이 설정하면 정상적으로 다운로드받는 것을 확인할 수 있다.\n$ export GOPRIVATE=private_repo_url  모듈 버전 업 문제  모듈의 버전은 v1에서 v2로 변경해서 다운로드받으려는 경우 다음과 같이 에러가 발생했다.\ngo get github.com/gomodule/module@v2.0.0: github.com/gomodule/module@v2.0.0: invalid version: module contains a go.mod file, so major version must be compatible: should be v0 or v1, not v2  다음과 같이 go.mod 파일을 수정하면 다운로드받을 수 있다.\nmodule github.com/gomodule/module/v2  참고 문헌  https://github.com/golang/go/issues/25886 https://golang.org/cmd/go/#hdr-Module_configuration_for_non_public_modules https://github.com/golang/go/issues/35732  ","date":"2020-04-23","permalink":"isprometheo.github.io/posts/58/","tags":["golang","test","timeout","401","gone","version"],"title":"[Golang] Go를 사용하면서 발생했던 문제들"},{"content":"Spring Boot 프로젝트를 빌드를 하기위해 maven을 사용했는데 시간이 많이 들었다.\n평상시엔 별 탈 없이 사용했지만 긴급상황에서 빠르게 배포가 필요한 경우\n너무 오래 걸려 빌드를 빠르게 하기 위해 Gradle로 전환할 필요를 느꼈다.\n그래서 찾아보니 다음과 같이 하면 간단하게 maven에서 gradle로 전환할 수 있었다.\n$ gradle init  변환을 하면 build.gradle, gradelw, settings.gradle 등이 만들어진다.\nbuild.gradle를 보면 repositories에 mavenLocal()이 기본으로 설정돼있는데\n외부 라이브러리를 호출하기 위해 mavenCentral로 변경했다.(다른 걸로 해도 된다.)\n여기까지는 쉽게 됐는데 실행 가능한 jar 파일을 만드는 게 어려웠다.\n우선 jar로 만들기 위해 build.gradle에 jar 태스크를 추가했다.\n그리고 gradle build로 빌드를 하고 jar를 실행했지만 클래스를 찾지 못한다는 에러가 발생했다.\n검색해보니 Spring Boot의 경우 plungins에 org.springframework.boot를 추가해야 했다.\nplugins { id 'java' id 'maven-publish' id 'org.springframework.boot' version '2.2.6.RELEASE' } repositories { mavenCentral() maven { url = 'https://repo.spring.io/milestone' } maven { url = 'http://repo.maven.apache.org/maven2' } } jar { manifest { attributes 'Main-Class': 'com.my.Application' } from { configurations.compile.collect { it.isDirectory() ? it : zipTree(it) } } }  위와 같이 build.gradle를 수정하고 만든 jar를 실행하니 잘 동작하는 것을 확인할 수 있었다.\norg.springframework.boot의 버전은 자신의 프로젝트에서 사용한 버전을 쓰면 된다.\n참고 문헌  https://docs.gradle.org/current/userguide/declaring_repositories.html https://docs.spring.io/spring-boot/docs/current/gradle-plugin/reference/html/ https://www.baeldung.com/gradle-fat-jar  ","date":"2020-04-09","permalink":"isprometheo.github.io/posts/57/","tags":["java","maven","gradle"],"title":"[Java] Maven을 Gradle로 전환하기"},{"content":"HADOOP을 설치하고 웹에서 파일을 추가하거나 삭제할 수 있는데\n다음과 같은 에러가 나면서 되지 않았다.\nPermission denied: user=dr.who, access=WRITE, inode=\u0026quot;/path/to/file\u0026quot;:current_user:supergroup:drwxr-xr-x  현재 HADOOP이 실행되고 있는 환경의 사용자 권한이 추가되지 않아 생기는 에러로\netc/hadoop/core-site.xml에 다음을 추가하고 재시작하면 된다.\n\u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hadoop.http.staticuser.user\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;current_user\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt;  참고 문헌  https://github.com/infoscis/Wiki/wiki/Pseudo-distributed-Hadoop(YARN)-설치  ","date":"2020-04-02","permalink":"isprometheo.github.io/posts/56/","tags":["log","hadoop"],"title":"[Log] HDFS Web UI Permission denied"},{"content":"golang 프로젝트의 로그를 수집하기 위해 confluent-kafka-go를 이용했다.\n이를 위해서 librdkafka를 설치해야 하는데\nconfluent-kafka-go 최신 버전의 경우 1.3.0 이상을 사용해야 한다는 에러가 났다.\nCeontOS 7에서 yum으로 설치하는 경우 0.11.x로만 가능해서 생긴 문제로\n최신 버전은 바이너리 파일을 제공하지 않아 직접 빌드해야 했다.\n다음과 같이 저장소를 받아서 태그를 1.3.0으로 변경했다.\n최신은 1.4.0-RC4 이지만 아직 정식이 아니라 1.3.0으로 했다.\n$ git clone https://github.com/edenhill/librdkafka.git $ cd librdkafka $ git checkout tags/v1.3.0 -b v1.3.0 $ cd librdkafka  librdkafka에서 packaging/rpm/Makefile을 보면 mock를 이용하여 rpm 파일을 생성한다.\n$ sudo yum install -y mock $ sudo usermod -a -G mock current_user $ cd packaging/rpm $ make  pkg-1.3.0-1-default 디렉토리 밑에 rpm 파일이 생긴 것을 확인할 수 있다.\n$ sudo yum install -y librdkafka1-1.3.0-1.el7.x86_64.rpm $ sudo yum install -y librdkafka-devel-1.3.0-1.el7.x86_64.rpm  위와 같이 설치해주면 confluent-kafka-go를 에러없이 사용할 수 있다.\n참고 문헌  https://github.com/confluentinc/confluent-kafka-go https://github.com/edenhill/librdkafka  ","date":"2020-03-26","permalink":"isprometheo.github.io/posts/55/","tags":["log","golang","kafka"],"title":"[Log] librdkafka 빌드하기"},{"content":"ELK를 구성하여 로그를 잘 쌓고 있었는데 어느 날 로그가 수집되고 있지 않았다.\n원인을 찾기 위해 Logstash의 로그(/var/log/logstash/logstash-plain.log)를 열어봤다.\n[INFO ][logstash.outputs.elasticsearch] retrying failed action with response code: 403 ({\u0026quot;type\u0026quot;=\u0026gt;\u0026quot;cluster_block_exception\u0026quot;, \u0026quot;reason\u0026quot;=\u0026gt;\u0026quot;blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];\u0026quot;})  위의 로그가 많이 있어 검색을 해보니 ElasticSearch에 용량이 부족할 경우\nKibana에서 인덱스를 읽기 전용으로 변경한다는 내용이었다.\nElasticSearch의 저장 공간 사용량을 확인해보니 90% 넘게 차있었다.\n이를 해결하기 위해 우선은 다음과 같이 쿼리를 날려 로그를 다시 수집할 수 있도록 했다.\nPUT http://ElasticSearch:9200/_all/_settings { \u0026quot;index\u0026quot;: { \u0026quot;blocks\u0026quot;: { \u0026quot;read_only_allow_delete\u0026quot;: \u0026quot;false\u0026quot; } } }  그리고 인덱스를 지워 용량을 확보해 로그들을 다시 쌓을 수 있었다.\n참고 문헌  https://dev-yeon.tistory.com/12  ","date":"2020-03-19","permalink":"isprometheo.github.io/posts/54/","tags":["log","logstash","elasticsearch"],"title":"[Log] Logstash 403 에러 해결"},{"content":"Spark에서 하는 일을 주기적으로 수행하기 위해 무엇이 있는지 조사했다.\n여러 가지 도구들이 있었는데 그 중에서 Airflow와 Luigi가 좋아보였다.\n둘 중에 어떤 걸로 정할 지 고민하다 Airflow로 정했다.\n두 가지 모두 좋아보였지만 Airflow가 Apache에서 관리하고 대시보드가 유려해보였다.\nAirflow를 설치하는 방법은 Quick Start에 잘 나와 있어 그대로 따라하면 된다.\n$ pip install 'apache-airflow[ssh]'  ssh는 원격 서버에 접속하여 spark-submit을 수행하기 위해 설치했다.\n$ airflow initdb  ~/airflow/에 airflow.cfg, airflow.db, logs, unittests.cfg 가 만들어진다.\nAirflow를 구동할 때 airflow webserver와 같이 커맨드로만 가능해서\n다음과 같이 start-airflow.sh, stop-airflow.sh을 만들어서 실행했다.\n#!/bin/sh nohup airflow webserver \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 \u0026amp; nohup airflow scheduler \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 \u0026amp;  #!/bin/sh pkill -f airflow  신규로 DAG를 만들기 위해서 ~/airflow에 dags 디렉토리를 만들고 파일을 추가한다.\n$ cd ~/airflow $ mkdir dags \u0026amp;\u0026amp; cd dags $ touch my_first_dag.py  my_fist_dag.py에 다음과 같이 작성하여 spark-submit을 주기적으로 수행하도록 했다.\n# -- coding: utf-8 -- from datetime import timedelta import airflow from airflow.models import DAG from airflow.contrib.operators.ssh_operator import SSHOperator from airflow.contrib.hooks.ssh_hook import SSHHook args = { 'owner': 'Airflow', 'start_date': airflow.utils.dates.days_ago(2), } dag = DAG( dag_id='my_dag', default_args=args, schedule_interval='0 0 * * *', dagrun_timeout=timedelta(minutes=60), tags=['spark'] ) templated_bash_command = \u0026quot;\u0026quot;\u0026quot; spark-submit \\ --class my_class \\ --master spark://spark-master:7077 \\ --executor-cores 2 \\ --executor-memory 2g \\ my_first.jar \u0026quot;\u0026quot;\u0026quot; hook = SSHHook( ssh_conn_id='ssh_default', remote_host='spark-master', username='username', key_file='~/.ssh/id_rsa' ) run_ssh = SSHOperator( task_id='spark_submit_task', ssh_hook=hook, command=templated_bash_command, dag=dag ) run_ssh  schedule_interval='0 0 * * *'은 하루에 한 번 밤에 수행한다고 문서에 적혀있는데\nUTC 시간대로 동작하여 한국 시간으로는 오전 9시에 수행한다.\n참고 문헌  http://bytepawn.com/luigi-airflow-pinball.html https://airflow.apache.org/docs/stable/installation.html https://airflow.apache.org/docs/stable/scheduler.html#dag-runs  ","date":"2020-03-12","permalink":"isprometheo.github.io/posts/53/","tags":["log","airflow","spark"],"title":"[Log] Airflow 설치"},{"content":"Zeppelin은 웹 기반으로 다양한 인터프리터를 이용해서 데이터 분석을 도와주는 도구이다.\n설치를 위해서 다음과 같이 하면 된다.\n$ sudo yum install -y java-1.8.0-openjdk.x86_64 $ wget http://mirror.apache-kr.org/zeppelin/zeppelin-0.8.2/zeppelin-0.8.2-bin-all.tgz $ tar xf zeppelin-0.8.2-bin-all.tgz \u0026amp;\u0026amp; cd zeppelin-0.8.2-bin-all  다음과 같이 실행하면 Zeppelin이 구동된다.\n$ bin/zeppelin-daemon.sh start  서버에 설치한 경우엔 직접 아이피로 접근해야 하는데 기본 설정으로는 접근할 수 없다.\nZeppelin 최신 버전(0.8.2)의 경우 기본 호스트가 0.0.0.0에서 127.0.0.1로 변경됐다.\nUpgrading from Zeppelin 0.8.1 (and before) to 0.8.2 (and later) From 0.8.2, Zeppelin server bind 127.0.0.1 by default instead of 0.0.0.0. Configure zeppelin.server.addr property or ZEPPELIN_ADDR env variable to change.  그래서 zeppelin-env.sh에서 ZEPPELIN_ADDR를 0.0.0.0으로 변경하고 재시작하면 웹에서 접근할 수 있다.\nSpark와 연동하기 위해서 Zeppelin이 설치된 서버에 Spark를 설치한다.\n원격 서버에 설치된 Spark 버전이 2.4.5라면 똑같은 버전을 설치해야 동작한다.\n그리고 zeppelin-env.sh에 다음과 같이 설정한다.\nexport SPARK_HOME=~/spark  이제 마지막으로 웹페이지에서 Interpreter에 Spark를 찾아 설정을 추가한다.\nmaster에 spark://remote_addr:7077와 같이 입력하면 된다.\nNotebook에서 테스트해보면 잘 동작하는 것을 확인할 수 있다.\n참고 문헌  https://zeppelin.apache.org/docs/0.8.2/setup/operation/upgrading.html#upgrading-from-zeppelin-07-to-08 https://stackoverflow.com/questions/50173371/how-to-solve-java-io-invalidclassexception-local-class-incompatible-with-scala  ","date":"2020-03-05","permalink":"isprometheo.github.io/posts/52/","tags":["log","spark","zeppelin"],"title":"[Log] Zeppelin 설치 및 Spark 연동"},{"content":"다음과 같이 각 서버에 Fluentd를 설치해 수집하는 서버로 로그를 전송하고\nKafka를 일종의 버퍼로 하여 ELK 스택이나 다른 것들을 이용할 수 있도록 구성했다.\n각 서버에서 tail로 로그 파일을 읽어서 forward로 송/수신하고 있었는데\n이 과정에서 다음과 같은 에러가 발생하며 누락 혹은 지연되는 경우가 발생했다.\n[warn]: #0 failed to flush the buffer. retry_time=0 next_retry_seconds=... chunk=\u0026quot;...\u0026quot; error_class=Fluent::Plugin::ForwardOutput::NoNodesAvailable error=\u0026quot;no nodes are available\u0026quot;  worker를 늘려 보기도 하고 버퍼 설정을 바꿔보기도 했지만 위의 에러는 계속 나왔다.\n원인이 무엇인지 한동안 못찾다가 UDP 방화벽을 열어줘야한다는 글을 봤다.\n그래서 문서를 보니 forward 통신을 할 때 heartbeat을 보내는 설정이 있었다.\ntransport가 기본값이라 tcp로 바꿔보니 해당 에러가 더이상 나지 않았다.\n(아마도 기본값인 경우 udp로도 전송하는데 막혀있어 에러가 난 것으로 생각된다.)\n하지만 1초(기본값)마다 heartbeat을 보내서 로그 전송 속도가 눈에 띄게 줄었다.\nheartbeat을 굳이 필요없어 none으로 하니 속도가 빨라진 것을 확인할 수 있었다.\n참고 문헌  https://qiita.com/kentokento/items/60b6654d4eea1dad5f42 https://docs.fluentd.org/output/forward#heartbeat_type  ","date":"2020-02-27","permalink":"isprometheo.github.io/posts/51/","tags":["log","fluentd"],"title":"[Log] NoNodesAvailable 에러 해결"},{"content":"React Native 버전을 0.59에서 0.61로 업데이트하면서 Hermes를 사용해보기로 했다.\nHermes 설정을 완료하고 앱을 구동했으나 다음과 같은 에러가 발생했다.\nRangeError: Maximum call stack size exceeded, js engine:hermes  릴리스 버전으로 빌드를 시도해봤지만 메모리 문제로 빌드가 되지 않았다.\ngradle emitting JVM memory status event {Maximum: 1431830528, Committed: 434634752}  이유가 무엇인지 찾아보니 앱에서 JSON 파일을 사용하고 있었는데 이 파일이 너무 커서 생긴 문제였다.\n이 문제를 해결하기 위해 Hermes를 안쓰고 해봤지만 앱 사이즈가 0.59 일 때보다 커졌다.\n그래서 Hermes를 쓰면서 동작하게 할 수 있는 방법을 찾다가 SQLite를 사용하기로 했다.\n여러 라이브러리가 있지만 react-native-sqlite-storage를 이용했다.\nandroid/src/main/assets/data 로 디렉토리를 만들고 파일을 넣는다.\n다음과 같이 하면 만든 DB 파일에 쉽게 접근할 수 있었다.\nimport SQLite from 'react-native-sqlite-storage'; class App extends Component { constructor() { super(); const db = SQLite.openDatabase({ name: 'test.db', location: 'deault', createFromLocation: '~data/test.db' }, () =\u0026gt; {}, error =\u0026gt; console.log(err)); this.state = { db, data: [] } } componentWillUnmount() { const { db } = this.state; db.close(); } componentDidMount() { const { db } = this.state; db.transaction(tx =\u0026gt; { tx.executeSql('SELECT * FROM test;', [], (tx, results) =\u0026gt; { const rows = results.rows; const data = rows.raw().map(v =\u0026gt; v); this.setState({ data }); }); }); } ... }  $ npm install react-native-sqlite-storage  하지만 위와 같이 설치하면 되는데 막상 구동시켜보면 아래와 같은 에러가 나왔다.\njava.lang.NoSuchMethodError: No interface method pushMap  다음과 같이 패치가 된 것을 설치하면 더이상 java.lang.NoSuchMethodError는 나오지 않았다.\n$ npm install react-native-sqlite-storage@andpor/react-native-sqlite-storage#pull/405/head  참고 문헌  https://github.com/facebook/hermes/issues/135 https://dev-yakuza.github.io/ko/react-native/react-native-sqlite-storage/ https://github.com/andpor/react-native-sqlite-storage/issues/387#issuecomment-575307816  ","date":"2020-02-20","permalink":"isprometheo.github.io/posts/50/","tags":["react native","sqlite"],"title":"[React Native] SQLite 사용하기"},{"content":"mp3 파일들을 연속으로 재생할 수 있는 웹페이지를 만들었다.\n처음엔 단순하게 audio 태그를 이용하여 재생했다.\n데스크톱에서 확인했을 때 잘 동작해서 문제가 없다고 생각했다.\n그런데 모바일에서 확인해보니 처음 재생은 화면이 꺼져도 끝까지 잘 됐지만 다음 파일이 재생되지 않았다.\n그래서 화면이 꺼지든가 브라우저가 백그라운드로 가도 재생이 되도록 해보려고 방법을 찾아봤다.\n그러다가 PWA로 하면 원하는 기능이 되지 않을까 해서 찾아봤다.\n찾아보니 PWA로 만든 음악 플레이어가 있어서 가능성이 보여 예제를 찾아 만들어 보기로 했다.\n다음은 예제 코드를 참고하여 간단하게 PWA를 만든 코드 일부분이다.\nmanifest.json 파일을 만들어서 추가한다.\n홈 화면에 추가했을 때 아이콘과 스플래시 화면이 나오도록 설정할 수 있다.\n{ \u0026quot;description\u0026quot;: \u0026quot;Play mp3 files.\u0026quot;, \u0026quot;display\u0026quot;: \u0026quot;standalone\u0026quot;, \u0026quot;icons\u0026quot;: [ { \u0026quot;src\u0026quot;: \u0026quot;icon/icon-64.png\u0026quot;, \u0026quot;sizes\u0026quot;: \u0026quot;64x64\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;image/png\u0026quot; } ], \u0026quot;name\u0026quot;: \u0026quot;PWA Test\u0026quot;, \u0026quot;short_name\u0026quot;: \u0026quot;PWA Test\u0026quot;, \u0026quot;start_url\u0026quot;: \u0026quot;/index.html\u0026quot;, \u0026quot;background_color\u0026quot;: \u0026quot;#3367D6\u0026quot;, \u0026quot;theme_color\u0026quot;: \u0026quot;#3367D6\u0026quot; }  그리고 Service Worker를 등록하면 된다.\nService Worker는 브라우저가 백그라운드에서 실행하는 스크립트로 웹페이지와는 별개로 작동하며\n웹페이지 또는 사용자 상호작용이 필요하지 않은 기능을 사용할 수 있게 해준다.\nindex.html에 Service Worker를 등록하는 코드를 추가한다.\n... \u0026lt;head\u0026gt; \u0026lt;link rel=\u0026quot;manifest\u0026quot; href=\u0026quot;/manifest.json\u0026quot;\u0026gt; \u0026lt;link rel=\u0026quot;apple-touch-icon\u0026quot; sizes=\u0026quot;180x180\u0026quot; href=\u0026quot;/icons/icon-64.png\u0026quot;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;script type=\u0026quot;text/javascript\u0026quot;\u0026gt; if('serviceWorker' in navigator) { navigator.serviceWorker .register('/pwa-examples/a2hs/sw.js') .then(function() { console.log('Service Worker Registered'); }); } \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; ...  sw.js 파일에 다음 코드를 추가한다.\nself.addEventListener('install', function(e) { e.waitUntil( caches.open('cache').then(function(cache) { return cache.addAll([ '/', '/index.html', '/script.js', '/style.css', '/icon.png' ]); }); ); }); self.addEventListener('fetch', function(e) { e.respondWith( caches.match(e.request).then(function(response) { return response || fetch(e.request); }); ); });  iOS에서 사파리로 접속한 다음 홈 화면에 추가를 하면 설정한 아이콘 모양으로 홈 화면에 추가된다.\n화면이 꺼지거나 앱을 종료해도 재생이 되는지 테스트했지만 재생이 되지 않았다.\n하지만 안드로이드에서는 화면이 꺼지거나 앱을 꺼도 재생이 잘되는 것을 확인할 수 있었다.\n참고 문헌  https://github.com/mdn/pwa-examples https://developers.google.com/web/fundamentals/web-app-manifest https://developers.google.com/web/fundamentals/primers/service-workers?hl=ko  ","date":"2020-02-13","permalink":"isprometheo.github.io/posts/49/","tags":["js","pwa"],"title":"[JS] PWA 만들기"},{"content":"시스템 환경설정 \u0026gt; 개인 정보 보호 \u0026gt; 전체 디스크 접근 권한에 Emacs 앱을 추가했지만\n홈 디렉토리를 제외한 문서, 다운로드 등의 디렉토리 접근이 불가능했다.\n이유는 Emacs가 ruby로 실행되기 때문이었다.\n전체 디스크 접근 권한에 /usr/bin/ruby를 추가하면 모든 디렉토리에 접근할 수 있다.\nEmacs is built on various versions of Mac OS X: 10.6, 10.7 and 10.9 as of this writing. The 10.6 builds also build 32-bit and PowerPC binaries (only Emacs 24 builds PowerPC—Emacs dropped support for it in Emacs 25). The later OSes only build 64-bit builds. All the binaries are combined into a single executable and a small Ruby launcher chooses which binary to run based on the machine's OS and architecture.  usr 디렉토리가 안보이는 경우 Command + Shift + .을 입력하면 숨겨진 디렉토리가 나온다.\n참고 문헌  https://emacs.stackexchange.com/questions/53026/how-to-restore-file-system-access-in-macos-catalina https://github.com/caldwell/build-emacs/blob/master/launch.rb  ","date":"2020-02-06","permalink":"isprometheo.github.io/posts/48/","tags":["emacs","macOS","Catalina"],"title":"[Emacs] macOS Catalina 디렉토리 접근 문제 해결"},{"content":"기존에 Java로 만들어진 프로젝트를 Golang으로 다시 만들고 있는데\n문자열을 gzip으로 압축한 뒤 base64로 인코딩한 결과를 파일명으로 만드는 로직이 있었다.\n처음엔 Golang에서도 gzip과 base64가 있어 이를 이용하면 당연히 결과가 같을 거라 생각했다.\n하지만 인코딩한 결과가 Java에서 수행한 결과와 달랐다.\n그래서 무엇이 다른지 16진수로 결과를 보니 헤더의 OS 값 및 압축된 값이 달랐다.\nRFC 문서를 보면 다음과 같이 헤더가 정의돼있었다.\n+---+---+---+---+---+---+---+---+---+---+ |ID1|ID2|CM |FLG| MTIME |XFL|OS | (more--\u0026gt;) +---+---+---+---+---+---+---+---+---+---+  ID1, ID2는 고정값으로 Java와 Golang 둘 다 1F 8B로 같았다.\nCM은 압축 방법인데 두 언어 다 deflate(08)로 같았다.\nFLG는 bit 단위로 설정하는데 0 ~ 3 비트만 설정이 가능하고 나머진 사용하지 않는다.\n이 값도 두 언어 모두 00으로 같았다.\nMTIME은 수정 시간으로 이 값 또한 00 00 00 00 으로 같았다.\nXFL은 추가 플래그로 2 또는 4의 값을 갖는다고 문서에는 나와있으나 두 언어 모두 00으로 돼있었다.\n마지막으로 OS는 현재 운영체제가 무엇인지 나타내는 값인데 Java에서는 00, Golang에서는 FF였다.\n헤더에서 OS 값만 달라 0으로 값을 설정했지만 압축한 결과는 여전히 달랐다.\n코드를 보니 다른 언어들과는 달리 Golang은 deflate를 직접 구현해서 사용하고 있었다.\n그래서 Golang의 소스를 수정해보려고 했지만 복잡하고 시간이 꽤 걸릴 것 같았다.\n차선으로 Java, Python 또는 Node로 API 서버를 띄워서 결과값을 반환 받는 방법이 생각했다.\n이 중에 Python은 특이하게도 MTIME은 수정이 가능하지만 OS는 수정이 불가능했다.\n하지만 서버 통신이 번거로운 것 같아 shell로 할 수 있는지 찾아보았다.\n다음과 같이 shell로 만들어서 Java와 같은 결과를 얻을 수 있었다.\necho -n $INPUT | gzip -c | xxd -s 10 -p -u -c 1000000 | xargs printf '1F8B0800000000000000%s' | xxd -r -p | openssl enc -a -A | tr -d '=' | tr '/+' '_-'  echo로 아무 옵션이 없을 때 gzip 결과를 확인해보니 실제 문자열보다 한글자 더 길었다.\n그래서 -n 옵션을 주어 정확히 해당 문자열만 나오도록 했다.\ngzip 명령어에서 MTIME과 OS를 변경하는 옵션이 없어 16진수로 변경한 뒤 앞의 헤더를 치환했다.\n참고 문헌  https://tools.ietf.org/html/rfc1952#page-5 https://github.com/Moodstocks/moodstocks-api-clients/blob/master/bash/base64url.sh http://fibrevillage.com/scripting/502-how-to-compress-string-in-bash  ","date":"2020-01-29","permalink":"isprometheo.github.io/posts/47/","tags":["golang","java","gzip"],"title":"[Golang] Java gzip migration"},{"content":"로그를 ElasticSearch에 쌓아서 실시간으로 보고 있었는데 로그의 양이 많아서 차지하는 용량이 계속 커지고 있었다.\n파일로도 로그를 남겨두기는 해서 한동안은 80 ~ 90% 정도 되면 인덱스를 지워서 용량을 확보했다.\n하지만 다년간의 추이를 보기 위해 로그를 분석해서 남겨야할 필요가 있었다.\nSpark와 Parquet를 조사하면서 요구 사항을 어떻게 적용할 수 있을지를 고심했었다.\n처음엔 ELK 스택처럼 Kafka로 로그를 받아서 처리하는 방식으로 하려고 시도했었다.\nSpark 예제에서 Kafka로 로그를 받아서 단어 개수를 세는 프로그램이 있어 이를 활용하면 되겠다 싶었다.\n하지만 로그를 받는 것은 쉽게 됐지만 Parquet로 저장하는 것이 쉽지 않았다.\n왜냐하면 Parquet는 열 지향 데이터 스토리지 형식이기 때문에 지속적으로 들어오는 데이터를 쓰는 것이 쉽지 않았다.\n그래서 중간에 Avro나 다른 DB에 저장했다가 하루가 지나면 Parquet로 저장하면 되겠다고 생각하고 golang으로 대강 완성을 했었다.\n그러다가 우연히 한 블로그를 발견하고 ElasticSearch에서 Parquet로 변환하여 장기보관하도록 수정했다.\n저장된 인덱스들로 테스트를 해봤는데 여러 가지 애로 사항을 겪을 수 있었다.\n우선은 필드명에 점(.)이 들어가 있는 경우 저장하려고 하면 다음과 같은 에러가 발생했다.\norg.elasticsearch.hadoop.rest.EsHadoopParsingException: org.elasticsearch.hadoop.EsHadoopIllegalStateException: Position for 'nested.foo.bar' not found in row; typically this is caused by a mapping inconsistency  원인은 Parquet로 저장하려면 csv 처럼 중첩되지 않은 표 형식으로 되어야하는데 열의 개수는 같지만 필드명이 각각 달라서 발생한 문제였다.\n그래서 해당 필드명만 추출해서 하면 되지 않을까 해서 es.query 설정도 해보고 filter 기능을 사용해서 해봤지만 결과는 같았다.\n어떻게 하면 가능할지 방법을 찾아보다가 테이블 형태로 추출한 다음에 Paquet로 저장하면 되지 않을까 하고 생각했다.\n예제 코드는 다음과 같다.\n// es.nodes는 ElasticSearch 주소, es.resource는 인덱스명 val esConf = Map( \u0026quot;es.nodes\u0026quot; -\u0026gt; \u0026quot;elasticsearch\u0026quot;, \u0026quot;es.resource\u0026quot; -\u0026gt; \u0026quot;index\u0026quot; ) val rdd = sc.esRDD(esConf) // 필드명에 .이 있는 경우 조회할 때 제대로 안돼서 변경 val result = rdd.map(_._2).map(x =\u0026gt; x.map { case (key, value) =\u0026gt; key.replace(\u0026quot;.\u0026quot;, \u0026quot;_\u0026quot;) -\u0026gt; value }) val keys = Array( \u0026quot;foo_bar_1\u0026quot;, \u0026quot;foo_bar_2\u0026quot; ) val rowRDD = result.map( x =\u0026gt; { val temp = scala.collection.mutable.Map[String, AnyRef](\u0026quot;@timestamp\u0026quot; -\u0026gt; x(\u0026quot;@timestamp\u0026quot;)) // 값이 없는 경우 \u0026quot;0.0\u0026quot;으로 설정 for (key \u0026lt;- keys if !x.contains(key)) temp += (key -\u0026gt; \u0026quot;0.0\u0026quot;) // 값이 있는 경우 문자열로 치환 for (key \u0026lt;- keys if x.contains(key)) temp += (key -\u0026gt; x(key).toString) // 타입을 명확히 하지 않으면 DataFrame을 만들 때 오류 발생 Row( new java.sql.Timestamp(temp(\u0026quot;@timestamp\u0026quot;).asInstanceOf[java.util.Date].getTime()), temp(\u0026quot;foo_bar_1\u0026quot;).asInstanceOf[String].toFloat, temp(\u0026quot;foo_bar_2\u0026quot;).asInstanceOf[String].toFloat ) }) val schema = StructType(Array( StructField(\u0026quot;@timestamp\u0026quot;, TimestampType, true), StructField(\u0026quot;foo_bar_1\u0026quot;, FloatType, true), StructField(\u0026quot;foo_bar_2\u0026quot;, FloatType, true) )) val df = spark.createDataFrame(rowRDD, schema) df.write.parquet(\u0026quot;hdfs://hadoop:9000/path/to/save/\u0026quot;)  Parquet로 저장할 때 권한이 없다면서 안되는 경우가 있는데 그때에는 다음과 같이 환경 설정에 HADOOP_USER_NAME을 추가하면 된다.\n$ export HADOOP_USER_NAME=hadoop  참고 문헌  http://jason-heo.github.io/elasticsearch/2016/06/28/elasticsearch-with-spark.html https://stackoverflow.com/questions/51097818/replace-special-characters-of-column-names-in-spark-dataframe https://stackoverflow.com/questions/32860831/how-can-i-change-sparkcontext-sparkuser-setting-in-pyspark  ","date":"2020-01-23","permalink":"isprometheo.github.io/posts/46/","tags":["log","spark","elasticsearch","parquet"],"title":"[Log] Spark ElasticSearch Parquet"},{"content":"Part 6 소프트웨어 이해하기  컴퓨터란 무엇인가?  인간이 설정한 목표를 달성하기 위해 일련의 기호 명령을 수행하고 데이터를 비교할 수 있는 모든 물질   소프트웨어 구성 요소: 구조, 동작, 결과 소프트웨어 개정판:(I)SAR 구별하기  구조: 프로그램의 구성 요소 동작: 일종의 동사 결과: 프로그램이 생산한 것   지식으로서의 소프트웨어 기술의 목적 간략하게 살펴보는 프라이버시 문제 단순성과 보안  보안을 지키는 최고의 방법은 단순성을 유지하는 것이다   테스트 주도 개발과 관찰 주기 테스트 철학  테스트의 전반적인 목표는 시스템에 관해 유효한 지식을 얻는 것이다.    6장에서는 소프트웨어가 무엇인가에 대해 설명한다.\n단순히 소프트웨어가 어떤 구성으로 돼있는지부터 어떤 방향으로 나아가는 것이 옳은 것인지를 이야기한다.\n또한, 테스트를 통해 소프트웨어 작동 방식을 이해하고 유지 보수할 수 있어\n테스트 방법을 정확히 이해하고 제대로 활용해야 한다고 말하고 있다.\nPart 7 나아지기  성공의 비밀: 나아지기  소프트웨어가 성공하려면 새 버전을 출시할 때마다 꾸준히 나아지면 된다   개떡 같은 부분을 찾는 방법  나아지고 싶다면 우선 가장 명백한 큰 문제를 찾아라 그리고 아무리 큰 수고가 들어도 꼭 해결하라   \u0026lsquo;아니요\u0026rsquo;의 힘 프로그래머가 개떡 같은 이유 빠른 프로그래밍의 비결: 생각하지 않기 개발자의 자만심  진정한 겸양의 미덕을 갖춘 개발자라면 사용자의 세계에 자신의 정체성을 드러내지 않는다   \u0026lsquo;일관성\u0026rsquo;과 \u0026lsquo;획일성\u0026rsquo;은 다르다 사용자는 문제를 알려주고 개발자는 해결책을 만든다 즉각적인 만족감 = 즉각적인 실페  소프트웨어는 언제나 장기적인 관점으로 보라   성공은 혁신이 아니라 실행에서 온다 훌륭한 소프트웨어  사용자의 명령을 정확하게 따른다 사용자가 예상한 대로 작동한다 사용자의 의도 전달을 막지 않는다    7장에서는 소프트웨어가 나아지기 위한 방법을 알려준다.\n그리고 무엇이 소프트웨어를 나쁘게 만드는지를 이야기하면서 개발자가 알아야 할 것들을 말하고 있다.\n총평 이 책을 읽기 전에도 다른 많은 책들을 읽어서 소프트웨어 설계를 할 때 무엇을 고려해야 하는지 대강은 알고 있다고 생각했다.\n하지만 여전히 배움이 부족하다는 것을 한 장씩 읽어가면서 느꼈다.\n책 초반에 뛰어난 프로그래머가 되고 싶다면 자신이 하는 일을 제대로 이해하라라고 한다.\n이것과 같은 의미에서 나아지기의 프로그래머가 개떡 같은 이유에서 무엇을 배워야하는지 말하는데\n돌이켜 생각해보면 시간을 투자해서 뭔가를 익히는데 노력을 쏟은 적이 잘 없었던 것 같다.\n이제부터라도 책에 나온 대로 실행에 옮겨 더 나은 프로그래머가 될 수 있을 것 같다.\n [독서] 심플 소프트웨어를 읽고(1) [독서] 심플 소프트웨어를 읽고(2) [독서] 심플 소프트웨어를 읽고(3)  ","date":"2020-01-16","permalink":"isprometheo.github.io/posts/45/","tags":["독서","심플 소프트웨어"],"title":"[독서] 심플 소프트웨어를 읽고(3)"},{"content":"Part 3 단순성과 소프트웨어 설계 설계는 프로젝트 초반에 하라  미래를 고려하지 않으면 코드가 엉망으로 설계되고 너무 복잡해진다.   미래 예측의 정확성  미래 예측의 정확성은 시스템이 복잡해질수록, 예측하고자 하는 시점이 멀어질수록 낮아진다.   단순성과 엄격성  엄격한 애플리케이션일수록 더 단순하게 작성할 수 있다.   둘은 너무 많다 분별있는 소프트웨어 설계  3장에서는 올바른 소프트웨어 설계에 대한 방법을 알려준다.\n첫째 미래에 무슨 일이 일어날지는 모르겠지만 언제나 안정적으로 동작할 수 있도록 설계한다.\n둘째 변화를 고려해서 설계한다.\n셋째 작은 범위에서만 변경하고 항상 단위 테스트를 한다.\n넷째 규격화하고 작고 간단하게 유지하여 작업을 단순화한다.\nPart 4 디버깅 버그란 무엇인가?  프로그램이 프로그래머의 의도에 따라 움직이지 않는다 프로그래머의 의도가 사용자의 평범하고 합리적인 기대를 충족시키지 않는다 의도한 방식에 따라 정확히 수행하는데도 사용자의 기대에 못미친다면 새로운 기능이 필요하다는 말이다   버그의 원인  버그는 복잡성을 줄이지 못할 때 발생한다. 코드가 단순할수록 버그가 줄어든 것이다 프로그램의 모든 것이 단순해지도록 늘 노력하라   재발을 방지하라  소프트웨어에서 가장 신경 써야 할 부분은 미래다 문제가 제대로 해결괬는지 확인하는 일반적인 가이드라인: 아무도 그 문제에 다시는 주의를 기울일 필요가 없을 정도가 되어야 한다   디버깅의 기본 철학  디버깅은 본인이 아직 담을 모든다고 자각하는 데에서 시작해야 한다 정상 시스템의 작동 방식 기억하기 더 많은 데이터를 모을 수 있는 방법 알아내기 정상 시스템이 어떻게 작동하는지 알아낸다 문제의 원인을 아직 모른다는 사실을 인정한다 문제를 일으키는 원인이 무엇인지 알아낼 때까지 데이터를 살펴본다 증상이 아닌 원인을 고친다    4장에서는 버그가 무엇인지 그 버그를 어떻게 찾을 것인지를 알려준다.\n디버깅을 할 때 항상 생각해야할 것은 문제의 원인을 모른다는 것을 인정하는 것이다.\n그래서 원인이 무엇인지 알아낼 때까지 데이터를 살펴보고 원인을 수정해야 한다.\n다음 문장은 본인이 저런 식으로 했던 적이 많아 공감이 가서 발췌했다.\n내가 겪은 프로그래머 **대부분**은 버그가 생기면 자리를 잡고 앉아서 버그에 관해 생각해보거나 원인이 무엇일지 이야기하고 싶어 한다. - p79  Part 5 엔지니어링 팀에서 일하기  엔지니어링 생산성을 효과적으로 개선하기  개발자가 생각하는 문제가 무엇인지 알아내라 팀의 신뢰를 얻어라 친절한 태도를 갖추고 인내심을 발휘하라 자기 눈에만 보이는 문제 말고 사람들이 인지하고 있는 문제를 해결하라   개발자 생산성 측정하기  개발자의 생산성을 측정하려면 그 사람이 생산한 제품을 측정하라   소프트웨어 회사에서 코드 복잡성을 다루는 법  문제 목록 작성 팀 회의 버그 리포트 우선순위 선정: 제일 많이 괴롭히는 문제부터 과제: 각 작업자에게 버그 할당 계획: 언제 고칠지 결정   리팩토링할 때는 기능에 주목하라  일단 시간이 지날수록 시스템이 더 나빠지지 않고 더 나아지는 상태로 만드는 걸 첫번째 목표로 삼아라 리팩토링 한계를 설정하고 그 한계 내에서 제대로 작업하라 리팩토링 시 해당 코드의 제작 목적에 부합하지 않는 부분을 목적에 부합하게 바꿔라   친절과 코드  개발자 말고 코드에 대해 이야기하는 게 중요하다 친철한 태도로 다른 이와 협력해서 더 나은 소프트웨어를 만들어라   간략하게 살펴보는 오픈 소스 커뮤니티  기여자 유지하기 장벽 없애기: 문서 작성 및 소통 채널 생성 관심 유도하기 아주 인기 있는 제품이 되라 인기 있는 프로그래밍 언어로 만들어라    5장에서는 생산성을 효과적으로 개선하기에서는 팀원들과의 소통이 중요하다는 것을 알려준다.\n저자가 참여했던 버그질라 프로젝트를 바탕으로 오픈 소스 프로젝트를 기획할 때 어떻게 하는게 좋은지 보여준다.\n이는 오픈 소스에만 국한되는 게 아니라 회사에서 프로젝트를 수행할 때도 같다고 생각한다.\n문서나 안내가 없다면 중간에 들어와 일하는 경우 어려움을 겪을 것이다.\n그리고 잘 안 쓰는 언어로 돼있다면 그 언어를 배우는데 시간을 허비해 업무 생산성이 떨어질 것이다.\n [독서] 심플 소프트웨어를 읽고(1) [독서] 심플 소프트웨어를 읽고(2) [독서] 심플 소프트웨어를 읽고(3)  ","date":"2020-01-09","permalink":"isprometheo.github.io/posts/44/","tags":["독서","심플 소프트웨어"],"title":"[독서] 심플 소프트웨어를 읽고(2)"},{"content":"페이스북에서 \u0026ldquo;심플 소프트웨어\u0026quot;라는 책이 나왔다고 해서 어떤 내용인지 궁금해서 읽어 보았다.\n책 표지에 다음과 같은 문장이 눈길을 끌었다.\n100년 뒤에도 유용할 소프트웨어 설계 원칙 \u0026amp; 프로그래머의 바른 길!\n코드의 단순성, 가독성, 안정성, 유지보수\n단순함을 추구하라! 더 나은 프로그래머가 될 것이다!\n뒷면에는 할 거면 잘 해라라는 문장이 맨 처음 크게 쓰여 있어\n책이 무엇을 말하고자 하는지 대강 눈치챌 수 있었다.\n파트는 총 7개로 나눠져 있는데 각 파트의 내용을 간략하게 정리해봤다.\nPart 1 프로그래머를 위한 원칙  할 거면 잘하라 엔지니어의 자세: 나는 이 문제를 올바른 방법으로 해결할 수 있다 자신이 하는 일을 제대로 이해하라 소프트웨어 설계  구현에 드는 수고보다 유지 보수에 드는 수고를 줄이는 게 더 중요하다 유지 보수에 드는 수고는 시스템의 복잡성에 비례한다    1장에서는 능력자 프로그래머가 될 수 있는 방법을 알려준다.\nPart 2 소프트웨어의 복잡성과 원인 복잡성의 단서 API 분리  나쁜 API는 공개하지 않는다 공개한 API는 망가뜨리지 않는다   유용하고 중요한 새 기능을 추가할 때 하위 호환성이 방해된다면 하위 호환성을 무시해도 된다 복잡성은 감옥이고 단순성은 자유다  2장에서는 어떤 소프트웨어가 복잡한 것인지와 어떻게 복잡해지는지를 설명한다.\n그리고 그 복잡성이 본인을 가두어버릴 수 있기에 단순성을 추구해야한다고 말하고 있다.\n [독서] 심플 소프트웨어를 읽고(1) [독서] 심플 소프트웨어를 읽고(2) [독서] 심플 소프트웨어를 읽고(3)  ","date":"2020-01-02","permalink":"isprometheo.github.io/posts/43/","tags":["독서","심플 소프트웨어"],"title":"[독서] 심플 소프트웨어를 읽고(1)"},{"content":"ejs를 2에서 3으로 업그레이드하고 나서 다음과 같은 에러가 발생했다.\nSyntaxError: Unexpected identifier in index.ejs while compiling ejs If the above error is not helpful, you may want to try EJS-Lint: https://github.com/RyanZim/EJS-Lint Or, if you meant to create an async function, pass `async: true` as an option. at new Function (\u0026lt;anonymous\u0026gt;) ...  에러 로그에서 어디에서 잘못됐는지 정확히 나오지도 않고\n로그에서 나온 주소에서는 해결 방법을 찾을 수 없어 막막했다.\n그래서 코드를 전부 제거하고 하나씩 찾아나가는 방법으로 어디가 문제인지를 찾았다.\n원인은 include 하는 기존 방식이 제거돼서 에러가 발생했던 것이었다.\n\u0026lt;% include ./header %\u0026gt;와 같이 돼있던 부분을 \u0026lt;%- include('header') %\u0026gt;와 같이 수정하면 된다.\n참고 문헌  https://github.com/mde/ejs/issues/476  ","date":"2019-12-26","permalink":"isprometheo.github.io/posts/42/","tags":["js","ejs","syntaxerror"],"title":"[JS] ejs SyntaxError"},{"content":"Golang을 1.13으로 업그레이드를 하고 프로젝트에서\ngo get ...으로 라이브러리를 다운받으려고 했는데\n410 Gone 에러를 내면서 실행이 되지 않았다.\n구글에서 검색을 해보니 해결 방법을 바로 찾을 수 있었다.\n$ export GO111MODULE=on $ export GOPROXY=direct $ export GOSUMDB=off  원인은 GOPROXY와 GOSUMDB 때문이었다.\n기존에 1.12 버전을 사용하고 있었는데 GOPROXY와 GOSUMDB 환경 변수가 없었고\n1.13으로 업그레이드를 했지만 설정되어 있지 않아 있어서 410 에러를 냈던 것이었다.\n참고 문헌  https://github.com/golang/go/issues/35164 https://golang.org/doc/go1.13  ","date":"2019-12-19","permalink":"isprometheo.github.io/posts/41/","tags":["golang","410","gone"],"title":"[Golang] 410 Gone"},{"content":"Lostash에서 input으로 kafka를 사용하고 있었는데 다음과 같은 오류가 나왔다.\n[WARN ][org.apache.kafka.common.utils.AppInfoParser] Error registering AppInfo mbean javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=logstash-1 at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436) ~[?:?] at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855) ~[?:?] at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955) ~[?:?] at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890) ~[?:?] at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320) ~[?:?] at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522) ~[?:?]  중복되는 설정들이 많아 합치면서 pipeline을 사용하도록 수정했는데\nLogstahs가 설정 파일을 각각의 pipeline마다 하나의 파일로 합쳐 사용하여\npipeline에 설정된 client_id가 서로 중복되어 발생한 문제였다.\n이전에는 pipeline을 사용하지 않고 개별로 설정하여 사용했는데 kafka도 개별로 사용하고 있었다.\n이때 문제가 되지 않았던 것은 Logstash가 설정 파일을 하나의 파일로 만들어서 사용하고\nclient_id가 같아도 자동으로 뒤에 숫자를 붙여 다른 client_id로 동작했기 때문이었다.\n다음과 같이 client_id를 설정할 때 postfix를 붙여서 pipeline마다 다른 client_id를 갖도록 수정했다.\ninput { kafka { bootstrap_servers =\u0026gt; \u0026quot;kafka_server:9092\u0026quot; client_id =\u0026gt; \u0026quot;logstash-postfix\u0026quot; ... } }  더이상 해당 오류가 발생하지 않고 kafka로부터 데이터를 잘 받아오는 것을 확인할 수 있었다.\n","date":"2019-12-12","permalink":"isprometheo.github.io/posts/40/","tags":["log","logstash","kafka"],"title":"[Log] Logstash Kafka 연동 에러 해결"},{"content":"Logstash에서 pipeline으로 개별로 설정을 하여 로그를 수집할 수 있다.\n그래서 input, filter, output으로 나누어 사용하기 위해\n다음과 같이 디렉토리를 구분하여 pipelines.yml을 설정했다.\n- pipeline.id: input path.config: \u0026quot;/etc/path/to/input.conf\u0026quot; - pipeline.id: filter path.config: \u0026quot;/etc/path/to/filter.conf\u0026quot; - pipeline.id: outpue path.config: \u0026quot;/etc/path/to/output.conf\u0026quot;  하지만 실제론 input만 동작하고 나머지는 non_running_pipelines로 되어 동작하지 않았다.\n다시 문서를 읽어보니 개별 설정마다 input이 있어야 했다.\n그래서 디렉토리에서 파일을 나눈 다음 순서대로 합쳐질 수 있도록 파일명을 수정했다.\nconf.d/ |- 01-input.conf |- 02-filter.conf |- 03-output.conf  그리고 pipelines.yml은 다음과 같이 수정하여 잘 동작하는 것을 확인할 수 있었다.\n- pipeline.id: input path.config: \u0026quot;/etc/path/to/*.conf\u0026quot;  참고 문헌  https://www.elastic.co/guide/en/logstash/current/multiple-pipelines.html https://www.elastic.co/guide/en/logstash/current/pipeline-to-pipeline.html  ","date":"2019-12-05","permalink":"isprometheo.github.io/posts/39/","tags":["log","logstash","pipeline"],"title":"[Log] Logstash Pipeline 사용하기"},{"content":"Fluentd에서 로그를 전송하는 부분을 수정한 이후로 잘 동작하고 있었지만\nflush_interval을 5분으로 하여 실시간으로 로그를 볼 수가 없었다.\n그리고 Fluentd 서버를 확인해 보니 로그 전송 버퍼가 많이 쌓여 있었다.\n그래서 버퍼를 빠르게 비우고 로그도 최대한 실시간으로 볼 수 있도록\nFluentd의 설정 문서를 읽어보면서 여러 가지들을 적용해보았다.\n우선은 버퍼 사이즈를 줄여보면서 쌓여있는 버퍼가 빠르게 전송되는지 확인해보았다.\n처음에는 buffer_queue_limit를 32로 buffer_chunk_limit를 2m로\n그 다음에는 buffer_queue_limit를 64, buffer_chunk_limit를 1m로\n테스트해보았지만 두번 다 버퍼는 계속 쌓였다.\n그래서 num_threads를 8로 적용해보니 버퍼가 빠르게 없어지는 것을 확인할 수 있었다.\n그리고 flush_interval을 1s로 줄여도 버퍼가 많이 쌓이지 않았고 Kibana를 통해 로그를 보니\n거의 실시간(30초 정도 지연)으로 처리되는 것을 확인할 수 있었다.\n최종적으로 설정한 값은 다음과 같다.\nbuffer_queue_limit 64 buffer_chunk_limit 1m flush_interval 1s num_threads 8  참고 문헌  https://docs.fluentd.org/v/0.12/output/kafka#buffer_queue_limit-buffer_chunk_limit  ","date":"2019-11-28","permalink":"isprometheo.github.io/posts/38/","tags":["log","fluentd","튜닝"],"title":"[Log] Fluentd 성능 튜닝"},{"content":"Javascript에서 정규식을 사용하는 경우가 자주 있는데 그때마다 잊어버리는 게 있다.\n반복해서 정규식을 이용해 문자열을 찾는 경우가 있는데\n항상 2번째에서는 다음과 같이 값이 나오지 않는 경우가 발생했다\nlet re = /ab/g; let str = 'abc' re.exec(str) ==\u0026gt; [\u0026quot;ab\u0026quot;] re.exec(str) ==\u0026gt; null  이유는 RegExp가 상태 저장(stateful)을 하기 때문이다.\n이를 위해 RegExp.lastIndex로 마지막으로 찾은 위치를 저장하는데\n위의 예시에서는 처음 수행하면 ab를 찾아서 값이 2가 된다.\n다음에 수행될 때는 마지막으로 찾은 위치부터 수행하기 때문에\n문자열을 찾지 못하고 lastIndex는 0으로 리셋된다.\n그래서 반복해서 정규식으로 문자열을 찾으려면 정규식을 수행한 이후에\n항상 lastIndex를 0으로 설정해야 원하는 결과를 얻을 수 있다.\nre.lastIndex = 0;  참고 문헌  https://stackoverflow.com/questions/11477415/why-does-javascripts-regex-exec-not-always-return-the-same-value https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp/exec https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp/lastIndex  ","date":"2019-11-21","permalink":"isprometheo.github.io/posts/37/","tags":["js","regexp","재사용"],"title":"[JS] RegExp 재사용할 때 문제 해결"},{"content":"Vue로 된 프로젝트가 있는데 하나의 파일에서 화면을 전부 만들고 있었다.\n각 부분들을 컴포넌트로 만드는데 자식 컴포넌트에 값을 넘겨 주면서\nwatch로 변경을 감지할 수 있도록 하는 기능이 필요했다.\nv-model을 사용하면 쉽게 될 줄 알았는데 미처 생각하지 못한 부분이 있었다.\n자식 컴포넌트에서 값을 받은 것이 변경됐는지 이벤트를 보내는 부분을 잊고 있었다.\n공식 문서를 읽어보면서 어떻게 해야하는지를 알 수 있었다.\n다음은 문서에 나온 코드를 지금 사용하고 있는 방식으로 변경한 것이다.\nParent.vue\n\u0026lt;template\u0026gt; \u0026lt;Child v-model=\u0026quot;check\u0026quot; /\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;script\u0026gt; import Child from './Child.vue'; export default { name: 'Parent', data: () =\u0026gt; { return { check: true } }, watch: { check: val =\u0026gt; console.log(val) } } \u0026lt;/script\u0026gt;  Child.vue\n\u0026lt;template\u0026gt; \u0026lt;input type=\u0026quot;checkbox\u0026quot; :checked=\u0026quot;checked\u0026quot; @change=\u0026quot;$emit('change', $event.target.checked)\u0026quot; \u0026gt; \u0026lt;/template\u0026gt; \u0026lt;script\u0026gt; export default { name: 'Child', model: { prop: 'checked', event: 'change' }, props: ['checked'] }; \u0026lt;/script\u0026gt;  참고 문헌  https://kr.vuejs.org/v2/guide/components.html#컴포넌트의-v-model-사용자-정의 https://github.com/vuejs/vue/blob/dev/src/core/vdom/create-component.js#L250-L268  ","date":"2019-11-14","permalink":"isprometheo.github.io/posts/36/","tags":["vue","watch","component"],"title":"[JS] watch를 사용할 수 있는 컴포넌트 만들기"},{"content":"AdMob에서 정책을 위반하고 있다는 메일을 받았다.\n그래서 정책 센터에서 자세한 내용을 살펴보니 전면 광고의 문제였다.\n기존의 전면 광고 노출 시점은 스플래시 화면 -\u0026gt; 콘텐츠 로드 -\u0026gt; 전면 광고 순이었다.\n코드 상으로는 스플래시 화면 다음에 바로 전면 광고가 노출되는 것이었는데\n실제로는 타이밍 이슈가 있어 콘텐트가 보이고 나서 노출되고 있었다.\n콘텐츠가 보이고 나서 전면 광고가 노출되는 것이\n의도하지 않은 클릭을 유도하는 레이아웃이라고 판단한 것이라 생각했다.\n그래서 해결하기 위해서 스플래시 화면 다음에 바로 전면 광고가 나오도록 해야할 것 같았다.\n하지만 React Native에서 스플래시 화면 다음에 바로 전면 광고가 나오도록 하는 것이 어려웠다.\n첫번째로 광고를 호출하는 데 걸리는 시간이 있었고\n두번째로 메인 화면이 렌더링되어 노출되는 것을 막는 것이 어려웠다.\n그래서 AdMob 고객 센터의 구현 지침에서 허용되지 않는 전면 광고 구현을 다시 한번 자세히 읽어보았다.\n허용되지 않은 방법 해결 방법 위의 해결 방법을 자세히 보고 나서 전면 광고 노출 시점을\n스플래시 화면 -\u0026gt; 로딩 중 -\u0026gt; 전면 광고 -\u0026gt; 콘텐츠 로드 순으로 변경했다.\n변경하여 플레이 스토어에 배포를 한 다음 AdMob에 검토 요청을 했다.\n검토 요청을 하는데 일주일 걸릴 수도 있다고 해서 기다리고 있었는데 금방 검토 메일이 날아왔다.\n\u0026ldquo;검토한 결과 정책 위반이 발견되지 않았습니다\u0026quot;라는 메일을 받았다.\n참고 문헌  https://support.google.com/admob/answer/6201362  ","date":"2019-11-07","permalink":"isprometheo.github.io/posts/35/","tags":["admob"],"title":"[AdMob] 정책 위반 해결"},{"content":"기존에 사용하던 라이브러리로 AdMob 광고를 표시하고 있었는데\n정책 위반 메일을 받아서 이를 처리할 필요가 있었다.\n그래서 react-native-admob 저장소에서 문서를 읽어봤다.\nisReady 메소드로 처리가 가능하겠다는 생각이 들었다.\n그러다 우연히 react-native-firebase에서 AdMob 라이브러리가 생긴 것을 확인했다.\n기존에 사용하던 것은 아직 beta였지만\nreact-native-firebase에서는 정식 버전이라 더 안정적으로 보여 변경하기로 했다.\n$ npm install @react-native-firebase/admob $ react-native link @react-native-firebase/admob  프로젝트 디렉토리에 firebase.json을 만들고 다음을 추가한다.\n{ \u0026quot;react-native\u0026quot;: { \u0026quot;admob_android_app_id\u0026quot;: \u0026quot;ca-app-pub-xxxxxxxx~xxxxxxxx\u0026quot;, \u0026quot;admob_ios_app_id\u0026quot;: \u0026quot;ca-app-pub-xxxxxxxx~xxxxxxxx\u0026quot; } }  사용법은 다음과 같다.\nimport { AdEventType, BannerAd, BannerAdSize, InterstitialAd, TestIds } from '@react-native-firebase/admob' const interstitialAd = InterstitialAd.createForAdRequest(TestIds.INTERSTITIAL); interstitial.onAdEvent((type) =\u0026gt; { if (type === AdEventType.LOADED) { interstitial.show(); } } interstitial.load(); \u0026lt;BannerAd unitId={TestIds.BANNER} size={BannerAdSize.SMART_BANNER} requestOptions={{ requestNonPersonalizedAdsOnly: true, }} onAdLoaded={() =\u0026gt; { console.log('Advert loaded'); }} onAdFailedToLoad((error) =\u0026gt; { console.error('Advert failed to load: ', error); }) /\u0026gt;  참고 문헌  https://github.com/invertase/react-native-firebase/tree/master/packages/admob  ","date":"2019-10-31","permalink":"isprometheo.github.io/posts/34/","tags":["react native","admob"],"title":"[React Native] AdMob 라이브러리 변경"},{"content":"Javascript 라이브러리를 만든 후 버전별로 빌드할 필요가 생겼다.\nalpha/beta/release 이렇게 빌드를 하려고 했는데 생각처럼 되지 않아 시행착오를 여러 번 겪었다.\nGrunt와 Webpack을 사용하여 빌드하고 있는데\nWebpack은 env 파라미터에서 버전 정보를 받아서 빌드하도록 했다.\n또한 버전별로 주소가 바뀌는 값이 있어 이를 동적으로 처리하기 위해 DefinePlugin을 이용했다.\nJavascript에서 DefinePlugin에 정의된 키가 해당 값으로 자동으로 변경되어 빌드된다.\n여기서 값을 설정할 때 중요한 것이 JSON.stringify로 값을 감싸줘야 제대로 동작한다.\nwebpack.config.js는 다음과 같이 작성하며 된다.\nconst webpack = require('webpack'); const path = require('path'); const config = require('./config.json'); module.exports = env =\u0026gt; { if (!env || !env. VERSION) { env = { ...env, VERSION: 'release' }; } const filename = env. VERSION === 'release' ? 'main.min.js' : `${env. VERSION}-main.min.js`; return { entry: './src/index.ts', target: 'node', mode: 'production', module: { rules: [ ... ] }, resolve: { extensions: [ '.ts', '.js' ] }, plugins: [ new webpack.DefinePlugin({ SPECIFIC_URL: JSON.stringify(config.contexts[env.VERSION].SPECIFIC_URL) }) ], output: { filename: filename, path: path.resolve(__dirname, 'dist') } }; };  다음과 같이 실행하면 된다.\n$ webpack --env.VERSION=release  그리고 한번에 버전별로 빌드하기 위해 Grunt를 사용했다.\n버전이 추가되도 자동으로 동작할 수 있도록 reduce를 이용했다.\n다음과 같이 작성하여 사용하고 있다.\nconst path = require('path'); const webpackConfig = require('./webpack.config.js'); const versions = ['alpha', 'beta', 'release']; module.exports = function(grunt) { grunt.initConfig({ pkg: grunt.file.readJSON('package.json'), webpack: versions.reduce((obj, version) =\u0026gt; { const app = version === 'release' ? 'app' : `${version}-app`; obj[app] = webpackConfig({VERSION: version}); return obj; }, {}) }); grunt.loadNpmTasks('grunt-webpack'); grunt.registerTask('default', ['webpack']); };  참고 문헌  https://webpack.js.org/guides/environment-variables/ https://webpack.js.org/plugins/define-plugin/  ","date":"2019-10-24","permalink":"isprometheo.github.io/posts/33/","tags":["js","grunt","webpack"],"title":"[JS] Grunt Webpack 버전별로 빌드하기"},{"content":"Sidecar 기능을 이용해보려고 Catalina로 업그레이드를 했다.\n하지만 갖고 있는 기기인 iPad mini 4는 지원 대상이 아니었다.\n그리고 Emacs도 사용하기가 살짝 까다로워졌다.\n이유는 폴더 접근 권한 때문인데 Emacs에서 폴더 접근 권한을 줄 수 없어\n특정 폴더의 파일들을 읽을 수 가 없었다.\n문서 폴더에 workspace를 만들어서 사용하고 있는데 해당 폴더에 접근을 할 수 없었다.\n이를 해결하기 위해 시스템 환경설정 \u0026gt; 보안 및 개인 정보 보호 \u0026gt; 개인 정보 보호 탭에서\n전체 디스크 접근 권한을 허용했지만 접근을 할 수 없었다.[1]\n그리고 어떤 분이 해결책이라고 올려준 fix-emacs-permissions-catalina.el를 해봤지만\n마찬가지로 문서 폴더에 접근할 수 없었다.\n그래서 이제 Emacs를 못쓰는 건가 하다가 XEmacs, Aquamacs를 설치해보기로 했다.\nXEmacs는 버전이 좀 오래되기도 하고 Aquamacs가 좀더 유려해 보여 Aquamacs를 설치해보니\n문서 폴더에도 접근이 잘 되어 Aquamacs를 사용하기로 결정했다.\n기존에 사용하던 기능들 대부분을 쓸 수 있었지만 iedit을 더이상 쓸 수가 없었다.\n왜냐면 iedit 기능을 시작할 때 C-;를 입력해야 하는데 해당 커맨드가\nOption 키를 메타키로 지정/해제하는 커맨드로 돼있었기 때문이다.\n그래서 multiple-cursors를 이용하여 iedit을 대체하여 사용하고 있다.\n참고 문헌  https://emacs.stackexchange.com/questions/53026/how-to-restore-file-system-access-in-macos-catalina https://gist.github.com/dive/f64c645a9086afce8e5dd2590071dbf9 https://github.com/magnars/multiple-cursors.el  ","date":"2019-10-17","permalink":"isprometheo.github.io/posts/32/","tags":["emacs","aquamacs"],"title":"[Emacs] macOS Catalina 업그레이드 문제"},{"content":"발표 자료를 만드는데 REVEAL.JS라는 라이브러리가 있어 활용해보고 싶었다.\n처음부터 만들어야 하나 하다가 org-reveal이라는 Emacs 패키지를 찾았다.\nGitHub의 문서를 참고하여 발표 자료를 다 만들고 html로 추출하는데 에러가 발생했다.\n문제를 해결하기 위해 GitHub의 Issues에서 찾아 적용해보니 바로 해결됐다.\n다음과 같이 Emacs에서 명령을 입력하면 된다.\nC-u M-x org-reload  참고 문헌  https://github.com/yjwen/org-reveal/issues/148  ","date":"2019-10-10","permalink":"isprometheo.github.io/posts/31/","tags":["emacs","reveal"],"title":"[Emacs] Reveal 추출 안되는 문제"},{"content":"Echo로 개발하여 API로 통신하는데 Content-Type: text/plain으로 통신을 해야했다.\nfunc(c echo.Context) (err error) { body := \u0026amp;Body{} if err = c.Bind(body); err != nil { return } return c.JSON(http.StatusOK, body) }  위와 같이 echo.Context.Bind를 이용하여 JSON 형식을 파싱하여 사용하고 있었는데\nContent-Type: text/plain인 경우 415 Unsupported Media Type 에러가 발생했다.\n말 그대로 지원하지 않는 미디어 형식이라 에러가 난 것이다.\n이를 해결하기 위해서 다음과 같이 변경하면 Content-Type에 무관하게 동작하도록 할 수 있다.\nfunc(c echo.Context) (err error) { rBody := \u0026amp;RegisterBody{} if b, err := ioutil.ReadAll(c.Request().Body); err == nil { if err := json.Unmarshal(b, \u0026amp;body); err != nil { return } } return c.JSON(http.StatusOK, body) }  참고 문헌  https://github.com/labstack/echo/issues/156#issuecomment-124684206  ","date":"2019-10-03","permalink":"isprometheo.github.io/posts/30/","tags":["golang","echo","415"],"title":"[Golang] Echo 415 에러 해결"},{"content":"애드센스 페이지에 들어가보니 PIN 번호를 입력하라는 문구가 나왔다.\n그래서 눌러보니 우편으로 발송한 PIN 번호를 입력하면 된다고 설명이 돼있었다.\n2~4주 정도 걸린다고 설명이 돼있는데다가 추석도 있어서 더 걸릴 줄 알았는데 2주만에 왔다.\n뜯으라는 부위를 다 뜯으면 열어볼 수가 있는데 그 안에 PIN 번호가 있었다.\n이 PIN 번호를 입력하고 나니 AdSense로 낸 수익을 받을 수 있구나라는 것이 실감이 났다.\n앞으로 AdSense 수익을 올릴 수 있는 방법들을 강구해봐야겠다.\n","date":"2019-09-19","permalink":"isprometheo.github.io/posts/29/","tags":["adsense","pin"],"title":"[AdSense] Google AdSense PIN 인증"},{"content":"로그를 분석하기 위해 Fluentd, Kafka, ELK(Elastic Search, Logstash, Kibana)를\n연동하여 사용하고 있는데 특정 토픽의 로그가 지연되고 있었다.\n처음엔 Logstash에서 Elastic Search로 전송하여 인덱싱하는 게 느린 것으로\n판단하여 Elastic Search의 설정을 다음과 같이 바꿨다.\nrefresh_interval: -1 number_of_replicas: 0  처음엔 되는 듯 싶었지만 여전히 로그가 지연되고 있어 혹시 Kafka에 제대로 들어오고 있는지를\n확인해보니 최근 메시지가 한참 이전의 메시지였다.\n그리고 Fluentd에서 Kafka로 전송하기 전에 버퍼 파일에 메시지를 쌓도록 돼있는데\n아직 전송되지 않은 메시지들이 파일들에 남아있었다.\n그래서 Fluentd의 로그를 살펴보니 다음과 같았다.\nbuffer flush took longer time than slow_flush_log_threshold: elapsed_time=329.28148816525936 slow_flush_log_threshold=20.0 plugin_id=\u0026quot;object:3ff42b981278\u0026quot;  버퍼를 비우는 시간이 설정된 시간보다 오래 걸려서 생긴 문제였다.\n다음과 같이 Fluentd의 설정을 변경하여 버퍼 파일을 작게 하고 비우는 시간을 1초에서 5분으로 늘렸다.\nbuffer_queue_limit 16 buffer_chunk_limit 4m flush_interval 5m num_threads 4 slow_flush_log_threshold 60.0  위와 같이 설정한 후로 기존에 쌓인 로그를 모두 Kafka로 전송할 수 있었고 로그가 지연되는 현상도 해결할 수 있었다.\n참고 문헌  https://m.blog.naver.com/PostView.nhn?blogId=inho1213\u0026amp;logNo=220774551220\u0026amp;proxyReferer=https%3A%2F%2Fwww.google.com%2F https://docs.fluentd.org/v/0.12/output/kafka  ","date":"2019-09-12","permalink":"isprometheo.github.io/posts/28/","tags":["log","fluentd","kafka","지연"],"title":"[Log] Fluentd Kafka 지연 해결"},{"content":"Emacs에서 C-x C-f로 helm-find-files를 사용하고 있었는데\n업데이트 이후에 디렉토리 및 파일을 탐색하는데\n화살표키로 상위 디렉토리로 가거나 이전으로 돌아오지 않고 커서가 움직였다.\n이전처럼 사용하기 위해 다음을 추가하면 된다.\n(define-key helm-map (kbd \u0026quot;\u0026lt;left\u0026gt;\u0026quot;) 'helm-previous-source) (define-key helm-map (kbd \u0026quot;\u0026lt;right\u0026gt;\u0026quot;) 'helm-next-source) (customize-set-variable 'helm-ff-lynx-style-map t)  참고 문헌  https://github.com/emacs-helm/helm/wiki/FAQ#arrow-keys-behavior-have-changed  ","date":"2019-09-05","permalink":"isprometheo.github.io/posts/27/","tags":["emacs","helm"],"title":"[Emacs] helm 화살표키 디렉토리 탐색"},{"content":"Gradle 버전을 5로 올리고 빌드를 하니\nreact-native-admob, react-native-custom-tabs, react-native-smart-splash-screen\n에서 다음과 같은 에러가 났다.\nerror: package android.support.annotation does not exist import android.support.annotation.Nullable; ^ error: cannot find symbol import android.support.customtabs.CustomTabsIntent; ^  이를 해결하려면 각각 다음과 같이 변경하면 된다.\n// import android.support.annotation.Nullable; import androidx.annotation.Nullable; // import android.support.customtabs.CustomTabsIntent; import androidx.browser.customtabs.CustomTabsIntent;  참고 문헌  https://developer.android.com/jetpack/androidx/migrate  ","date":"2019-08-29","permalink":"isprometheo.github.io/posts/26/","tags":["react native","androidx","migration"],"title":"[React Native] AndroidX Migration"},{"content":"앱을 빌드하는데 다음과 같은 에러가 발생했다.\n\u0026gt; Configure project :@react-native-firebase_analytics :@react-native-firebase_analytics:firebase.bom using default value: 21.1.0 FAILURE: Build failed with an exception. * Where: Build file '../node_modules/@react-native-firebase/analytics/android/build.gradle' line: 60 * What went wrong: A problem occurred evaluating project ':@react-native-firebase_analytics'. \u0026gt; Could not find method platform() for arguments [com.google.firebase:firebase-bom:21.1.0] on object of type org.gradle.api.internal.artifacts.dsl.dependencies.DefaultDependencyHandler.  android/gradle/wrapper/gradle-wrapper.properties에서 다음을 수정하면 된다.\n... distributionUrl=https\\://services.gradle.org/distributions/gradle-5.1.1-all.zip  그리고 .gradle 디렉토리를 제거하고 다시 앱을 빌드하면 된다.\n참고 문헌  https://stackoverflow.com/questions/57329362/error-could-not-find-method-platform-for-arguments-react-native-firebase  ","date":"2019-08-22","permalink":"isprometheo.github.io/posts/25/","tags":["react native","firebase","analytics","빌드 실패"],"title":"[React Native] 빌드 실패 해결(Firebase Analytics)"},{"content":"go로 개발을 하다가 TCP 통신을 해야 했는데 서버와 연결이 끊어지면 다시 시도를 하는 기능이 필요했다.\ngo가 아직은 익숙치않아 어떻게 구현해야 하는지 난감했지만 열심히 구글링해서 찾았다.\n채널을 통해서 하는 방법도 있고 다른 방법들도 있었지만 다음과 같이 하는 것이 가장 쉬웠다.\nimport ( \u0026quot;encoding/json\u0026quot; \u0026quot;io\u0026quot; \u0026quot;log\u0026quot; \u0026quot;net\u0026quot; \u0026quot;time\u0026quot; ) type Config struct { Address string `json:\u0026quot;address\u0026quot; form:\u0026quot;address\u0026quot;` } var ( conn net.Conn ) func Driver(config Config) { var err error for { conn, err = net.Dial(\u0026quot;tcp\u0026quot;, config.Address) if conn == nil || err != nil { log.Println(\u0026quot;Trying reset the connection...:\u0026quot;, config.Address, err.Error()) time.Sleep(time.Second * 1) } else { data := make([]byte, 4096) for { n, err := conn.Read(data) if err != nil { log.Println(err) if io.EOF == err { conn.Close() break } } if n \u0026gt; 0 { // TODO } } } } }  참고 문헌  https://stackoverflow.com/questions/54797902/golang-recursive-function-for-reconnecting-a-tcp-client-bad-idea  ","date":"2019-08-15","permalink":"isprometheo.github.io/posts/24/","tags":["golang","tcp","client","reconnect"],"title":"[Golang] TCP Client Reconnect"},{"content":"ELK를 이용하여 로그 수집/분석을 하기 위해 Fluentd와 Kafka를 연동할 필요가 있었다.\n그래서 Fluentd에서 Kafka로 로그를 전송할 수 있도록 설정을 추가했는데\nKafka가 죽어서(원인은 파악하지 못했다.) Fluentd가 설치된 로그 서버가 행이 걸리는 경우가 발생했다.\nretry_limit의 기본값이 17로 돼있어서 발생한 문제로 Kafka로 전송이 실패해서 버퍼가 계속 쌓인 상태에서\n해당 버퍼를 Kafka로 전송하려가 I/O가 가득 차 해당 서버가 행이 걸려 다른 서버로 절체된 것이었다.\nretry_limit을 1로 주고 테스트를 해보니 Kafka 전송에 실패해도 버퍼가 더이상 쌓이지 않는 것을 확인했다.\n\u0026lt;match\u0026gt; @type copy \u0026lt;store\u0026gt; @type kafka_buffered ... retry_limit 1 ... \u0026lt;/store\u0026gt; \u0026lt;/match\u0026gt;  Logstash에서 Kafka 연동할 때 토픽별로 인덱스를 설정해 Elastic Search에 저장하기 위해\nfilter와 output에 다음의 내용을 추가하면 된다.\nif [@metadata][kafka][topic] == \u0026quot;topic\u0026quot; { }  위의 설정을 추가하지 않는 경우 filter에서는 오류가 나지 않을 수도 있지만\noutput에서는 가장 먼저 설정된 인덱스만 인식하여 나머지 인덱스에는 저장이 되지 않는다.\n참고 문헌  https://docs.fluentd.org/v/0.12/output/kafka#retry_limit-disable_retry_limit  ","date":"2019-08-08","permalink":"isprometheo.github.io/posts/23/","tags":["log","fluentd","kafka","logstash"],"title":"[Log] Fluentd Kafka Logstash 연동"},{"content":"앱을 개발하다보니 설정된 내용을 저장할 필요가 있어 async-storage를 사용하게 되었다.\nReact Native 버전이 0.59 이하인 경우 아래와 같이 하면 된다.\n버전이 0.60 이상인 경우 link를 해주지 않아도 된다.\n$ npm install @react-native-community/async-storage $ react-native link @react-native-community/async-storage  데이터를 불러올 때 예제에서는 async, await 를 사용하는데\nconstructor에서는 사용할 수 없어 componentDidMount를 async 함수로 사용했다.\nconstructor() { super(); this.state = { ..., isLoading: true, ... }; } async componentDidMount () { ... try { const value = await AsyncStorage.getItem('key'); if (value !== null) { const data = JSON.parse(value); this.setState(data); } } finally { this.setState({isLoading: false}); } ... } storeData = async (value) =\u0026gt; { try { await AsyncStorage.setItem('key', value) } catch (e) { } }  isLoading을 넣어준 이유는 데이터를 읽은 후 setState 함수에서 상태를 변경하는데\n상태가 변경되기 전에 렌더링이 된 후 상태가 변경된 후 다시 렌더링을 되는 것을 막기 위해 추가했다.\n참고 문헌  https://github.com/react-native-community/async-storage  ","date":"2019-08-01","permalink":"isprometheo.github.io/posts/22/","tags":["react native","async storage"],"title":"[React Native] Async Storage 사용하기"},{"content":"현재 블로그 테마로 minima를 사용하고 있는데 메인 페이지에 페이지네이션 기능이 없었다.\n이를 위해 jekyll-paginate를 _config.yml과 Gemfile에 추가하면 된다.\n_config.yml 파일에 다음을 추가한다.\n... paginate: 5 paginate_path: \u0026quot;/page/:num/\u0026quot; plugins: ... - jekyll-paginate  Gemfile 파일에 다음을 추가한다.\ngroup :jekyll_plugins do ... gem \u0026quot;jekyll-paginate\u0026quot; end  그리고 페이지를 넣기 위해 예제 중에 하나를 home.html에 추가했고,\nsite.posts를 paginator.posts로 변경했다.\n{% raw %}{% if paginator.total_pages \u0026gt; 1 %} \u0026lt;div class=\u0026quot;pagination\u0026quot;\u0026gt; {% if paginator.previous_page %} \u0026lt;a href=\u0026quot;{{ paginator.previous_page_path | prepend: site.baseurl | replace: '//', '/' }}\u0026quot;\u0026gt;« Prev\u0026lt;/a\u0026gt; {% else %} \u0026lt;span\u0026gt;« Prev\u0026lt;/span\u0026gt; {% endif %} {% for page in (1..paginator.total_pages) %} {% if page == paginator.page %} \u0026lt;em\u0026gt;{{ page }}\u0026lt;/em\u0026gt; {% elsif page == 1 %} \u0026lt;a href=\u0026quot;{{ paginator.previous_page_path | prepend: site.baseurl | replace: '//', '/' }}\u0026quot;\u0026gt;{{ page }}\u0026lt;/a\u0026gt; {% else %} \u0026lt;a href=\u0026quot;{{ site.paginate_path | prepend: site.baseurl | replace: '//', '/' | replace: ':num', page }}\u0026quot;\u0026gt;{{ page }}\u0026lt;/a\u0026gt; {% endif %} {% endfor %} {% if paginator.next_page %} \u0026lt;a href=\u0026quot;{{ paginator.next_page_path | prepend: site.baseurl | replace: '//', '/' }}\u0026quot;\u0026gt;Next »\u0026lt;/a\u0026gt; {% else %} \u0026lt;span\u0026gt;Next »\u0026lt;/span\u0026gt; {% endif %} \u0026lt;/div\u0026gt; {% endif %} {% endif %}{% endraw %}  하지만 다음과 같은 에러가 나면서 동작하지 않았다.\nPagination: Pagination is enabled, but I couldn't find an index.html page to use as the pagination template. Skipping pagination.  여러 시행착오 끝에 index.md 파일을 index.html 파일로 변경하여 위 문제를 해결할 수 있었다.\n참고 문헌  https://jekyllrb-ko.github.io/docs/pagination/ https://github.com/jekyll/jekyll-paginate  ","date":"2019-07-25","permalink":"isprometheo.github.io/posts/21/","tags":["jekyll","minima"],"title":"[Jekyll] minima 테마에 페이지 넣기"},{"content":"앱을 올리고 한참이 지난 후 \u0026ldquo;정책 위반으로 Google Play에서 앱이 삭제되었습니다.\u0026ldquo;라는 내용의 메일을 받았다.\n내용을 읽어보니 대강 무엇이 문제인지는 바로 알 수 있었다.\n앱에서 애드몹(AdMob)과 애널리틱스(Firebase Analytics)를 사용하고 있었는데\n이에 대한 개인정보처리방침을 올리지 않았기 때문이라는 생각이 들었다.\n하지만 어떻게 대처해야 할지 몰라 난감했는데\n검색해보니 많을 분들이 이미 겪어 어떻게 해야하는지 금방 알 수 있었다.\n여기에서 개인정보처리방침을 만들 수 있다.\n그리고 해당 페이지를 Github이나 블로그 등에 올리고\n앱정보 \u0026gt; 스토어 등록정보 \u0026gt; 개인정보처리방침 에 주소를 넣고 업데이트하면 된다.\n참고 문헌  https://mnworld.co.kr/1901  ","date":"2019-07-18","permalink":"isprometheo.github.io/posts/20/","tags":["playstore","정책위반"],"title":"[PlayStore] 구글 플레이스토어 정책 위반 메일 대처 방법"},{"content":"앱을 배포한 이후에 비정상 종료에 다음과 같은 내용들이 올라왔다.\nCaused by: java.lang.ClassNotFoundException: at dalvik.system.BaseDexClassLoader.findClass (BaseDexClassLoader.java:93)  이를 해결하기 위해 검색한 결과 multidex를 추가하면 해결이 된다는 내용을 보고 추가하기로 했다.\n기본적인 내용들은 여기에서 보면 된다.\nAndroidX를 사용하고 있어서 이를 기준으로 내용을 추가했다.\ndependencies { ... implementation \u0026quot;androidx.multidex:multidex:2.0.1\u0026quot; ... }  attachBaseContext 함수를 추가할 때 라이브러리를 임포트해줘야하는데 다음과 같다.\n... import android.content.Context; import androidx.multidex.MultiDex; ... public class MainApplication extends Application implements ReactApplication { ... @Override protected void attachBaseContext(Context base) { super.attachBaseContext(base); MultiDex.install(this); } ... }  참고 문헌  https://developer.android.com/studio/build/multidex?hl=ko  ","date":"2019-07-11","permalink":"isprometheo.github.io/posts/19/","tags":["react native","multidex"],"title":"[React Native] MultiDex 추가"},{"content":"앱을 릴리즈로 빌드한 다음 실제 기기나 에뮬레이터에서 실행했을 때 충돌(Crash)이 나는 경우가 있다.\n이럴 땐 어디서 에러가 났는지 확인해야하는데 다음의 명령어로 로그를 확인할 수 있다.\n$ adb logcat *:E  zsh의 경우엔 다음과 같이 한다.\n$ adb logcat '*:E'  이번에 react-native-svg를 적용하면서 앱이 실행과 동시에 죽는 경우가 발생했다.\n이를 해결하기 위해 위의 명령어로 로그를 살펴보니 다음과 같이 나왔다.\n07-01 02:49:52.865 26792 26792 E AndroidRuntime: java.lang.IllegalStateException: java.lang.NoSuchFieldException: fill 07-01 02:49:52.865 26792 26792 E AndroidRuntime: at com.horcrux.svg.t.a(Unknown Source) 07-01 02:49:52.865 26792 26792 E AndroidRuntime: at com.horcrux.svg.ad.a(Unknown Source) 07-01 02:49:52.865 26792 26792 E AndroidRuntime: at com.horcrux.svg.t.d(Unknown Source) 07-01 02:49:52.865 26792 26792 E AndroidRuntime: at com.horcrux.svg.j.b(Unknown Source) 07-01 02:49:52.865 26792 26792 E AndroidRuntime: at com.horcrux.svg.j.a(Unknown Source) 07-01 02:49:52.865 26792 26792 E AndroidRuntime: at com.horcrux.svg.t.d(Unknown Source) 07-01 02:49:52.865 26792 26792 E AndroidRuntime: at com.horcrux.svg.j.b(Unknown Source) 07-01 02:49:52.865 26792 26792 E AndroidRuntime: at com.horcrux.svg.j.a(Unknown Source) 07-01 02:49:52.865 26792 26792 E AndroidRuntime: at com.horcrux.svg.t.d(Unknown Source) 07-01 02:49:52.865 26792 26792 E AndroidRuntime: at com.horcrux.svg.j.b(Unknown Source) 07-01 02:49:52.865 26792 26792 E AndroidRuntime: at com.horcrux.svg.j.a(Unknown Source) 07-01 02:49:52.865 26792 26792 E AndroidRuntime: at com.horcrux.svg.t.d(Unknown Source) 07-01 02:49:52.865 26792 26792 E AndroidRuntime: at com.horcrux.svg.x.a(Unknown Source) 07-01 02:49:52.865 26792 26792 E AndroidRuntime: at com.horcrux.svg.x.j(Unknown Source) 07-01 02:49:52.865 26792 26792 E AndroidRuntime: at com.horcrux.svg.x.onDraw(Unknown Source) 07-01 02:49:52.865 26792 26792 E AndroidRuntime: at android.view.View.draw(View.java:17185)  progaurd로 난독화를 한 후 찾지 못해서 난 오류로 해당 라이브러리를 난독화에서 제외하면 된다.\n해결 방법은 android/app/progauard-rules.pro에 다음을 추가하고 빌드하면 된다.\n-keep public class com.horcrux.svg.** {*;}  참고 문헌  https://github.com/react-native-community/react-native-svg/issues/481  ","date":"2019-07-04","permalink":"isprometheo.github.io/posts/18/","tags":["react native","firebase","충돌"],"title":"[React Native] Firebase 충돌 해결"},{"content":"앱을 배포한 이후에 사용자가 어떤 행동을 하는지 알고 싶어졌다.\n그래서 react-native-firebase를 이용하여 수집하기로 했다.\nyarn으로 설치하거나 다음을 실행하면 된다.\n$ npm install --save @react-native-firebase/app $ react-native link @react-native-firebase/app $ npm install --save @react-native-firebase/analytics $ react-native link @react-native-firebase/analytics  코드에 추가하는 방법은 3가지가 있는데 가장 간략한 방법으로 추가했다.\nimport analytics from '@react-native-firebase/analytics'; // analytics().X  다음의 함수들을 이용하여 로그를 수집할 수 있다.\nlogEvent resetAnalyticsData setAnalyticsCollectionEnabled setCurrentScreen setMinimumSessionDuration setSessionTimeoutDuration setUserId setUserProperties setUserProperty  참고 문헌  https://github.com/invertase/react-native-firebase/tree/master/packages/analytics https://github.com/invertase/react-native-firebase/tree/master/packages/app https://invertase.io/oss/react-native-firebase/v6/analytics/reference  ","date":"2019-06-27","permalink":"isprometheo.github.io/posts/17/","tags":["react native","firebase","analytics"],"title":"[React Native] Firebase Analytics 사용"},{"content":"react-native-webview를 사용할 때\ngradle.properties에 다음을 추가해야 한다.\nandroid.useAndroidX=true android.enableJetifier=true  추가한 후에 빌드할 때 react-native-admob에서 빌드 실패가 나는 경우가 발생한다.\n\u0026gt; Task :react-native-admob:compileDebugJavaWithJavac FAILED  이런 경우 jetifier를 설치하면 해결할 수 있다.\n$ npm install --save-dev jetifier $ npx jetify  참고 문헌  https://github.com/facebook/react-native/issues/25307 https://stackoverflow.com/questions/53235525/issues-using-androidx-and-react-native  ","date":"2019-06-20","permalink":"isprometheo.github.io/posts/16/","tags":["react native","webview"],"title":"[React Native] Webview 사용"},{"content":"react-native로 만든 앱에 광고를 넣기 위해 react-native-admob을 사용했다.(안드로이드만 사용)\n$ npm i --save react-native-admob@next $ react-native link react-native-admob@next  android/app/build.gradle에 다음을 추가한다.\ndependencies { ... implementation \u0026quot;com.google.firebase:firebase-core:17.0.0\u0026quot; implementation \u0026quot;com.google.firebase:firebase-ads:17.2.1\u0026quot; }  사용법은 다음과 같다.\nimport { AdMobBanner, AdMobInterstitial, PublisherBanner, AdMobRewarded, } from 'react-native-admob' // 배너 광고 \u0026lt;AdMobBanner adSize=\u0026quot;fullBanner\u0026quot; adUnitID=\u0026quot;your-admob-unit-id\u0026quot; testDevices={[AdMobBanner.simulatorId]} onAdFailedToLoad={error =\u0026gt; console.error(error)} /\u0026gt; // DFP(Doubleclick For Publisher) - 조건을 상세하게 커스터마이징할 수 있는 배너 \u0026lt;PublisherBanner adSize=\u0026quot;fullBanner\u0026quot; adUnitID=\u0026quot;your-admob-unit-id\u0026quot; testDevices={[PublisherBanner.simulatorId]} onAdFailedToLoad={error =\u0026gt; console.error(error)} onAppEvent={event =\u0026gt; console.log(event.name, event.info)} /\u0026gt; // 전면 광고 AdMobInterstitial.setAdUnitID('your-admob-unit-id'); AdMobInterstitial.setTestDevices([AdMobInterstitial.simulatorId]); AdMobInterstitial.requestAd().then(() =\u0026gt; AdMobInterstitial.showAd()); // 리워드 광고 AdMobRewarded.setAdUnitID('your-admob-unit-id'); AdMobRewarded.requestAd().then(() =\u0026gt; AdMobRewarded.showAd());  배너 광고를 추가한 뒤 에뮬레이터로 확인하면 경고가 뜨는데 이 경우엔 다음과 같이 하면 해결할 수 있다.\nnode_modules/react-native-admob/RNAdMobBanner.js에서\nUIManager.RNGADBannerView.Commands.loadBanner를\nUIManager.getViewManagerConfig('RNGADBannerView').Commands.loadBanner로 변경하면 된다.\n27 loadBanner() { 28 UIManager.dispatchViewManagerCommand( 29 findNodeHandle(this._bannerView), 30 UIManager.getViewManagerConfig('RNGADBannerView').Commands.loadBanner, 31 null, 32 ); 33 }  참고 문헌  https://github.com/sbugert/react-native-admob/issues/339  ","date":"2019-06-13","permalink":"isprometheo.github.io/posts/15/","tags":["react native","admob"],"title":"[React Native] Admob 사용"},{"content":"UPDATE\nReact Native에서 특정 폰트를 사용하기 위해서 폰트를 추가해야하는데 다음과 같이 하면 된다.\n fonts 디렉토리를 만들어 폰트를 넣어준다.  react-native-app │ README.md │ index.ios.js │ index.android.js └── ios └── android └── src │ │ │ └── assets │ └── fonts │ └── 폰트  package.json에 다음을 추가한다.  ... \u0026quot;rnpm\u0026quot;: { \u0026quot;assets\u0026quot;: [ \u0026quot;src/assets/fonts\u0026quot; ] }  다음 명령어를 실행하면 ios/andorid에 자동으로 폰트가 추가된다.  $ react-native link  다음처럼 스타일을 적용하는 부분에 넣어 사용하면 된다.  fontFamily: '폰트이름'  참고 문헌  https://medium.com/@mehran.khan/ultimate-guide-to-use-custom-fonts-in-react-native-77fcdf859cf4  ","date":"2019-06-06","permalink":"isprometheo.github.io/posts/14/","tags":["react native","폰트"],"title":"[React Native] 폰트 추가(2)"},{"content":"앱을 출시하기 위해서 빌드를 해야한다.\n keytool로 업로드 키를 생성한다.  my-upload-key.keystore와 my-key-alias는 변경해도 된다.\n$ keytool -genkeypair -v -keystore my-upload-key.keystore -alias my-key-alias -keyalg RSA -keysize 2048 -validity 10000  android/gradle.properties에 다음을 추가한다.  MYAPP_UPLOAD_STORE_FILE=my-upload-key.keystore MYAPP_UPLOAD_KEY_ALIAS=my-key-alias MYAPP_UPLOAD_STORE_PASSWORD=***** MYAPP_UPLOAD_KEY_PASSWORD=*****  android/app/build.gradle에 다음을 추가한다.  ... android { ... defaultConfig { ... } signingConfigs { release { if (project.hasProperty('MYAPP_UPLOAD_STORE_FILE')) { storeFile file(MYAPP_UPLOAD_STORE_FILE) storePassword MYAPP_UPLOAD_STORE_PASSWORD keyAlias MYAPP_UPLOAD_KEY_ALIAS keyPassword MYAPP_UPLOAD_KEY_PASSWORD } } } buildTypes { release { ... signingConfig signingConfigs.release } } } ...  릴리스용 APK를 생성한다.  $ cd android $ ./gradlew bundleRelease  andorid/app/build/outputs/bundle/release에 app.aab로 생성된다.\nCPU 아키텍처별로 APK를 생성한다.  ... def enableSeparateBuildPerCPUArchitecture = true ...  ./gradlew assembleRelease를 실행하면 CPU 아키텍처별로\nandorid/app/build/outputs/apk/release에 APK가 생성된다.\nandroid/app/build.gradle에 다음을 변경하면 파일 크기를 줄일 수 있다.  ... def enableProguardInReleaseBuilds = true ...  참고 문헌  https://facebook.github.io/react-native/docs/signed-apk-android  ","date":"2019-05-30","permalink":"isprometheo.github.io/posts/13/","tags":["react native","앱 빌드"],"title":"[React Native] 앱 빌드하기"},{"content":"React Native로 개발한 앱을 안드로이드 에뮬레이터로 보기위해선 다음을 실행하여 에뮬레이터를 먼저 실행해야 한다.\nandroid avd  하지만 무슨 이유에서인지 실행이 안되었는데 이유는 docker와 충돌이 나서였다.\n이를 해결하기 위해 docker를 종료하고 에뮬레이터를 실행하여 문제를 해결했다.\n참고 문헌  https://github.com/moby/moby/issues/24530  ","date":"2017-02-09","permalink":"isprometheo.github.io/posts/12/","tags":["react native","docker","emulator","충돌"],"title":"[React Native] docker와 android emulator 충돌"},{"content":"React Native에서 특정 폰트를 사용하기 위해서 폰트를 추가해야하는데 다음과 같이 하면 된다.\n fonts 디렉토리를 만들어 폰트를 넣어준다.  react-native-app │ README.md │ index.ios.js │ index.android.js └── ios └── android └── src │ │ │ └── assets │ └── fonts │ └── 폰트  rnpm을 설치한다.  $ npm install -g rnpm  package.json에 다음을 추가한다.  ... \u0026quot;rnpm\u0026quot;: { \u0026quot;assets\u0026quot;: [ \u0026quot;src/assets/fonts\u0026quot; ] }  다음 명령어를 실행하면 ios/andorid에 자동으로 폰트가 추가된다.  $ rnpm link assets  다음처럼 스타일을 적용하는 부분에 넣어 사용하면 된다.  fontFamily: '폰트이름'  참고 문헌  https://kylealwyn.com/blog/custom-fonts-with-react-native  ","date":"2017-02-02","permalink":"isprometheo.github.io/posts/11/","tags":["react native","폰트"],"title":"[React Native] 폰트 추가"},{"content":"Emacs에서 여러 창을 나누어 사용할 때 커서를 다른 창으로 이동하는 단축키는 C-x o 이다.\n하지만 창이 여러 개인 경우 이동하는 게 불편하다.\ninit.el에 다음을 추가하여 좀더 빠르게 커서를 다른 창으로 이동할 수 있다.\n(global-set-key (kbd \u0026quot;C-c \u0026lt;left\u0026gt;\u0026quot;) 'windmove-left) (global-set-key (kbd \u0026quot;C-c \u0026lt;right\u0026gt;\u0026quot;) 'windmove-right) (global-set-key (kbd \u0026quot;C-c \u0026lt;up\u0026gt;\u0026quot;) 'windmove-up) (global-set-key (kbd \u0026quot;C-c \u0026lt;down\u0026gt;\u0026quot;) 'windmove-down)  참고 문헌  https://www.emacswiki.org/emacs/WindMove  ","date":"2017-01-26","permalink":"isprometheo.github.io/posts/10/","tags":["emacs","window move"],"title":"[Emacs] Window Move"},{"content":"예전에 Emacs로 python 통합 개발 환경을 구성하기 위해서 여러 라이브러리들을 설치해본 적이 있었다.\n당시에는 ropemacs를 사용하여 다른 것보다도 자동 완성 기능을 할 수 있도록 했었다.\n최근에 다시 Python으로 개발하면서 elpy라는 것이 좋아 보여 계속 사용하고 있다.\n(setenv \u0026quot;PYTHONIOENCODING\u0026quot; \u0026quot;utf-8\u0026quot;) (setenv \u0026quot;LANG\u0026quot; \u0026quot;ko_KR.UTF-8\u0026quot;) (when (require 'elpy nil t) (elpy-enable)) (setq elpy-rpc-python-command \u0026quot;python2.7\u0026quot;) (setq elpy-rpc-backend \u0026quot;jedi\u0026quot;) (setq python-check-command \u0026quot;~/Library/Python/2.7/bin/flake8\u0026quot;) (add-hook 'python-mode-hook (lambda () (setq-default indent-tabs-mode t) (setq-default tab-width 4) (setq-default py-indent-tabs-mode t) (add-to-list 'write-file-functions 'delete-trailing-whitespace)))  python3도 설치되어 있어 python2.7을 사용하도록 elpy-rpc-python-command를 설정했다.\nflake8의 경우 2, 3에 각각 pip install --user flake8로 설치하고 python-check-command를 설정하여 사용하도록 했다.\n참고 문헌  Python Programming In Emacs Elpy manual  ","date":"2017-01-19","permalink":"isprometheo.github.io/posts/9/","tags":["emacs","python","개발 환경"],"title":"[Emacs] Python 개발 환경 구축"},{"content":"Emacs에서는 기본적으로 다른 에디터에서 많이 사용되는 기능 중에 하나인 한 줄을 위아래로 옮길 수 없다.\n이를 사용하기 위해서 init.el에 다음을 추가하면 된다.\n(defun move-line (n) \u0026quot;Move the current line up or down by N lines.\u0026quot; (interactive \u0026quot;p\u0026quot;) (setq col (current-column)) (beginning-of-line) (setq start (point)) (end-of-line) (forward-char) (setq end (point)) (let ((line-text (delete-and-extract-region start end))) (forward-line n) (insert line-text) ;; restore point to original column in moved line (forward-line -1) (forward-char col))) (defun move-line-up (n) \u0026quot;Move the current line up by N lines.\u0026quot; (interactive \u0026quot;p\u0026quot;) (move-line (if (null n) -1 (- n)))) (defun move-line-down (n) \u0026quot;Move the current line down by N lines.\u0026quot; (interactive \u0026quot;p\u0026quot;) (move-line (if (null n) 1 n))) (global-set-key (kbd \u0026quot;M-\u0026lt;up\u0026gt;\u0026quot;) 'move-line-up) (global-set-key (kbd \u0026quot;M-\u0026lt;down\u0026gt;\u0026quot;) 'move-line-down)  참고 문헌  https://www.emacswiki.org/emacs/MoveLine  ","date":"2017-01-12","permalink":"isprometheo.github.io/posts/8/","tags":["emacs","move line"],"title":"[Emacs] Move Line"},{"content":"Emacs org-mode에서 테이블을 만들 때 한글이 들어가는 경우 테이블이 깨지는 경우가 발생한다.\n이는 영어와 한글의 사이즈가 달라서 발생하는 문제로 폰트 크기를 설정해주면 해결할 수 있다.\n(set-face-font 'default \u0026quot;Monaco-12\u0026quot;) (set-fontset-font \u0026quot;fontset-default\u0026quot; '(#x1100 . #xffdc) '(\u0026quot;AppleGothic\u0026quot; . \u0026quot;unicode-bmp\u0026quot;)) (setq face-font-rescale-alist '((\u0026quot;AppleGothic\u0026quot; . 1.2)))  기본 폰트로 Monaco를, 한글 폰트는 AppleGothic으로 설정했고 한글은 1.2배 크게 나오도록 설정했다.\n위와 같이 하면 org-mode에서 테이블이 잘 나오는 것을 확인할 수 있다.\n참고 문헌  [Emacs] 24.x 버젼 한글 폰트 설정 \u0026amp; org-mode 의 한글 테이블 깨지지 않게 보이기  ","date":"2017-01-05","permalink":"isprometheo.github.io/posts/7/","tags":["emacs","org-mode","한글","테이블"],"title":"[Emacs] org-mode 한글 테이블"},{"content":"Django에서 일정 거리내의 데이터를 조회하려면 다음과 같은 API를 사용하면되는데 데이터베이스에 따라 사용할 수 있는 것이 제한되어 있다.\nSpatiaLite를 이용하는 경우에 distance_gt, distance_gte, distance_lt, distance_lte는 사용 가능하지만 해당 데이터베이스에서는 직교 좌표계에서 두점 간의 거리를 계산하는 방식으로 하기에 위도, 경도를 직교 좌표계에 맞게 바꿔서 저장해야 한다.\nx = R * cos(위도) * cos(경도) y = R * cos(위도) * sin(경도)  R 은 지구 반경 근사치로 약 6,371Km이다.\n위와 같은 식으로 변환한 뒤 조회를 하면 일정 반경 이내 혹은 이외의 데이터를 조회할 수 있다.\n","date":"2015-06-13","permalink":"isprometheo.github.io/posts/6/","tags":["python","geodjango"],"title":"[Python] GeoDjango"},{"content":"Django에서 로그를 남기려면 다음과 같이 하면 된다.\nsettings.py에 다음을 추가한다.\nLOGGING = { 'version': 1, 'disable_existing_loggers': False, 'handlers': { 'file': { 'level': 'DEBUG', 'class': 'logging.FileHandler', 'filename': '/path/to/log/debug.log', }, }, 'loggers': { 'django.request': { 'handlers': ['file'], 'level': 'DEBUG', 'propagate': True, }, 'django.request': { 'handlers': ['file'], 'level': 'DEBUG', 'propagate': True, }, ‘myproject': { 'handlers': ['file'], 'level': 'DEBUG', }, }, }  다음과 같이 작성하여 사용자 로그를 남길 수 있다.\n# logging 라이브러리를 추가한다. import logging # logger 인스턴스를 가져온다. # settings.py의 myproject에서 설정된 대로 로그를 남길 수 있다. logger = logging.getLogger(‘myproject.{}’.format(__name__)) def my_view(request, arg1, arg): ... if bad_mojo: # 에러 메시지를 남긴다. logger.error('Something went wrong!')  __name__은 아래와 같은 구조에서 users/views.py 인 경우 users.views를 뜻한다.\nmyproject/ manage.py myproject/ __init__.py settings.py urls.py wsgi.py users/ __init__.py models.py views.py urls.py  참고 문헌  https://docs.djangoproject.com/en/1.8/topics/logging/  ","date":"2015-05-10","permalink":"isprometheo.github.io/posts/5/","tags":["python","django","logging"],"title":"[Python] Django logging"},{"content":"Django 프로젝트의 settings.py에 다음을 추가한다.\nSTATIC_ROOT = os.path.join(BASE_DIR, 'static')  그리고 다음 명령어를 이용하여 Django에 내장된 static 파일을 지정한 디렉토리에 저장한다.\n$ python manage.py collectstatic  gunicorn 관련된 설정은 공식 문서와 예제 파일을 참고하여 작성한다. 그리고 다음과 같은 명령어로 실행한다.\n$ gunicorn -c gunicorn.conf.py {Django 프로젝트 이름}.wsgi \u0026amp;  nginx.conf에 다음과 같이 추가한다.\nhttp { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] \u0026quot;$request\u0026quot; ' '$status $body_bytes_sent \u0026quot;$http_referer\u0026quot; ' '\u0026quot;$http_user_agent\u0026quot; \u0026quot;$http_x_forwarded_for\u0026quot;'; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; # Load modular configuration files from the /etc/nginx/conf.d directory. # See http://nginx.org/en/docs/ngx_core_module.html#include # for more information. include /etc/nginx/conf.d/*.conf; index index.html index.htm; upstream app_server { server 127.0.0.1:8000; # For a TCP configuration: # server 192.168.0.7:8000 fail_timeout=0; } server { listen 80; server_name localhost; root /usr/share/nginx/html; #charset koi8-r; #access_log /var/log/nginx/host.access.log main; location /static { alias /path/static; # static 파일 위치 } location / { # root html; # index index.html index.htm; try_files $uri @proxy_to_app; } location @proxy_to_app { proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_redirect off; proxy_pass http://app_server; } }  위와 같이 수정한 설정 파일을 다시 읽는다.\n$ sudo /etc/init.d/nginx reload  혹은\n$ service nginx reload  static 파일을 제대로 불어오지 못하는 경우 nginx.conf에서 다음을 수정하면 된다.\n# user nginx # 기본으로 설정된 user가 nginx인 경우 root로 변경하거나 # static 파일 접근 권한이 있는 user로 변경한다. user root  ","date":"2015-04-12","permalink":"isprometheo.github.io/posts/4/","tags":["python","django","nginx","gunicorn"],"title":"[Python] nginx + gunicorn + Django"},{"content":"SQLite는 사용되는 응용 프로그램에 내장되는 놀라운 라이브러리이다. 독립적이고 파일 기반 데이터베이스로써 SQLite는 프로세스 기반 관계형 데이터베이스(서버)와 비교해봤을 때 제약이 덜하고 쉽게 정렬된 모든 데이터를 다루는 도구를 제공한다.\n응용 프로그램에서 SQLite를 사용할 때, 실용적으로 동작하고 인터페이스(예: 포트, 소켓)를 통한 통신을 하는 대신 데이터를 갖고 있는 파일(즉 SQLite 데이터베이스)을 만들어 직접 호출한다. 이 라이브러리의 기본 기술 덕분에 SQLite는 매우 빠르고 , 효율적이고, 또한 강력하다.\nSQLite에서 지원하는 데이터 타입  NULL: NULL 값 INTEGER: 부호가 있는 정수, 값의 크기에 따라 1, 2, 3, 4, 6, 8 바이트 저장 REAL: 부동소수점, 8 바이트 IEEE 부동소수점을 저장 TEXT: 문자열, 데이터베이스 인코딩에 따라 문자열 저장(UTF-8, UTF-16BE or UTF-16LE) BLOB: 이진 데이터, 들어온 데이터 그대로 저장  Note: SQLite의 데이터 타입에 대해 더 알고 싶다면 공식 문서를 확인\nSQLite의 장점  파일 기반: 이동이 용이하게 만들어진 파일 하나가 전체 데이터베이스이다. 표준을 따름: 간단한 DB 구현체이지만 SQLite는 SQL을 사용한다. 몇가지 기능(RIGHT OUTER JOIN, FOR EACH STATEMENT)이 생략되어 있지만 다른 기능들은 내장되어 있다. 개발과 테스트에 적합:여러 프로그램의 개발 단계에서 다수의 사람들을 위한 동시성을 측정할 수 있는 해결책을 필요로 한다. 풍부한 기능이 있는 SQLite는 단일 파일과 C 기반의 라이브러리로 동작의 단순함으로 개발에 필요한 것보다 더 많이 제공할 수 있다.  SQLite의 단점   사용자 관리가 없음: 고급 데이터베이스는 사용자 즉, 데이터베이스와 테이블에 접근 권한을 설정한 연결 관리 기능을 제공한다. SQLite의 목적과 특성(높은 레벨의 다수 클라이언트 동시 접속이 없음)으로 이 기능은 존재하지 않는다.\n  추가 성능을 위한 개조 가능이 어려움: 다시 설계되어서 SQLite는 추가 성능을 얻기 위해 손보는 게 불가능하다. 라이브러리는 튜닝하거나 사용하는데 편리하다. 복잡하지 않기 때문에 기술적으로 성능을 올리는 것이 불가능하다.\n  SQLite를 사용하는 때   임베디드 응용 프로그램: 확장하지 않으며 이동이 용이한 모든 응용 프로그램. 예를 들면, 단일 사용자 로컬 응용 프로그램, 모바일 프로그램 또는 게임.\n  디스크 접근 대체: SQL을 사용함으로써 나오는 추가 기능과 단순함 때문에 디스크에 파일을 읽고 쓰는 것이 필요한 대부분의 응용 프로그램은 SQLite로 전환하여 이득을 볼 수 있다.\n  테스트: 응용 프로그램의 많은 부분에서 비즈니스 로직(즉, 응용 프로그램의 주 용도: 기능)을 테스트하기 위한 추가 프로세스를 사용하는 것은 과잉이다.\n  SQLite를 사용하면 안되는 때   다수 사용자 응용프로그램: 다수 클라이언트가 접속하고 같은 데이터베이스를 사용하는 응용 프로그램인 경우 완벽한 기능을 갖춘 RDBM(예: MySQL)을 선택하는 것이 좋다.\n  높은 쓰기 볼륨을 원하는 응용 프로그램: SQLite의 제약 사항 중 하나는 쓰기 기능이다. 이 DBMS는 주어진 시간 동안 오직 하나의 쓰기만을 허락한다. 이런 이유로 제한된 처리량만 가능하다.\n  참고 문헌  https://www.digitalocean.com/community/tutorials/sqlite-vs-mysql-vs-postgresql-a-comparison-of-relational-database-management-systems  ","date":"2015-03-27","permalink":"isprometheo.github.io/posts/3/","tags":["db","sqlite"],"title":"[DB] SQLite"},{"content":"Postgresql에서 위치 정보를 저장하기 위해 PostGIS를 이용한다. postgis를 사용하기 위해서 geos, proj.4를 먼저 설치한다. geos는 Geometry Engine - Open Source의 약어로 좌표 계산에 사용되며, proj.4는 좌표 변환에 사용된다.\n$ wget http://download.osgeo.org/geos/geos-3.3.6.tar.bz2 $ tar xjf geos-3.3.6.tar.bz2 $ cd geos-3.3.6 $ ./configure $ make $ sudo make install $ wget http://download.osgeo.org/proj/proj-4.8.0.tar.gz $ wget http://download.osgeo.org/proj/proj-datumgrid-1.5.zip $ tar xzf proj-4.8.0.tar.gz $ cd proj-4.8.0/nad $ unzip ../../proj-datumgrid-1.5.zip $ cd .. $ ./configure $ make $ sudo make install $ wget http://download.osgeo.org/postgis/source/postgis-2.0.2.tar.gz $ tar xzf postgis-2.0.2.tar.gz $ cd postgis-2.0.2 $ ./configure --with-geosconfig=/usr/local/bin/geos-config --without-raster $ make $ sudo make install  잘 설치가 됐는지 확인한다. SRID 값으로 4326은 WGS(World Geodetic System) 84를 의미한다. 전세계 지구 좌표를 표현하는 방식 중에 하나로 이를 이용하여 거리를 계산할 수 있다.\nCREATE TABLE test_location (id SERIAL, name VARCHAR(24), geom geometry('POINT', 4326)); INSERT INTO test_location (name,geom) VALUES ('창경궁', ST_GeomFromText('POINT(126.99470043182373 37.58079163827203)', 4326)); SELECT id, name, ST_AsText(geom) from test_location;  ","date":"2014-07-18","permalink":"isprometheo.github.io/posts/2/","tags":["db","postgresql","postgis"],"title":"[DB] Postgresql + PostGIS"},{"content":"Django와 nginx를 연동하기 위해서 flup 라이브러리를 설치한다.\n$ pip install flup  Django 실행은 다음과 같다.\n$ python manage.py runfcgi method=prefork pidfile=PID_FILE host=127.0.0.1 port=8000  nginx.conf 에 다음과 같이 추가한다.\nserver { listen 80 server_name localhost; location /static/ { #static url autoindex on; root /static/; #static 파일들이 저장된 디렉토리 } location / { #사용할 url #root /usr/share/nginx/html; #index index.html index.htm; fastcgi_pass 127.0.0.1:8000; fastcgi_param PATH_INFO $fastcgi_script_name; fastcgi_param REQUEST_METHOD $request_method; fastcgi_param QUERY_STRING $query_string; fastcgi_param CONTENT_TYPE $content_type; fastcgi_param CONTENT_LENGTH $content_length; fastcgi_pass_header Authorization; fastcgi_intercept_errors off; } }  static url을 설정할 때 /static/으로 해서 파일을 불러오지 못할 경우 앞이나 뒤의 /를 제거하면 된다.\n위와 같이 수정한 설정 파일을 다시 읽는다.\n$ sudo /etc/init.d/nginx reload  ","date":"2013-11-04","permalink":"isprometheo.github.io/posts/1/","tags":["python","django","nginx"],"title":"[Python] nginx + Django"}]